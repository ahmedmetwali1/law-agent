"""
ğŸ¯ Ø¨Ø­Ø« Ù…Ø¨Ø§Ø´Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… source_id Ø§Ù„Ù…Ø¹Ø±ÙˆÙ
"""

import requests
import os
from dotenv import load_dotenv

load_dotenv()

SUPABASE_REST_URL = "http://152.67.159.164:8000/rest/v1"
SUPABASE_ANON_KEY = os.getenv("SUPABASE_ANON_KEY", "")

# Source ID Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø¯Ù†ÙŠØ© (Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…)
SOURCE_ID = "ca79a531-1e9b-4bef-b5b8-8d5482184e7e"

def get_headers():
    return {
        "apikey": SUPABASE_ANON_KEY,
        "Authorization": f"Bearer {SUPABASE_ANON_KEY}",
        "Content-Type": "application/json"
    }

print("=" * 70)
print("ğŸ¯ Ø¨Ø­Ø« Ù…Ø¨Ø§Ø´Ø± Ø¹Ù† 'Ø§Ù„Ù‡Ø¨Ø©' ÙÙŠ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø¯Ù†ÙŠØ©")
print("=" * 70)

# 1. ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù†Ø¸Ø§Ù…
print("\n1ï¸âƒ£ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†Ø¸Ø§Ù…...")
url = f"{SUPABASE_REST_URL}/legal_sources"
params = {"select": "id,title", "id": f"eq.{SOURCE_ID}"}
response = requests.get(url, headers=get_headers(), params=params)

if response.status_code == 200 and response.json():
    source = response.json()[0]
    print(f"   âœ… {source['title']}")
    print(f"   ID: {source['id']}")
else:
    print(f"   âŒ Ø®Ø·Ø£: {response.status_code}")
    exit()

# 2. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† "Ø§Ù„Ù‡Ø¨Ø©"
print("\n2ï¸âƒ£ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† chunks ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 'Ø§Ù„Ù‡Ø¨Ø©'...")
url = f"{SUPABASE_REST_URL}/document_chunks"
params = {
    "select": "id,content,sequence_number",
    "source_id": f"eq.{SOURCE_ID}",
    "content": "ilike.%Ø§Ù„Ù‡Ø¨Ø©%",
    "order": "sequence_number.asc",
    "limit": 10
}

response = requests.get(url, headers=get_headers(), params=params)

if response.status_code == 200:
    chunks = response.json()
    print(f"   âœ… ÙˆØ¬Ø¯Øª {len(chunks)} Ù†ØªÙŠØ¬Ø©!")
    
    if chunks:
        print("\n   ğŸ“„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
        for i, chunk in enumerate(chunks, 1):
            print(f"\n   {i}. Seq: {chunk['sequence_number']}")
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¯
            import re
            articles = re.findall(r'Ø§Ù„Ù…Ø§Ø¯Ø©\s*(\d+)', chunk['content'])
            if articles:
                print(f"      Ø§Ù„Ù…ÙˆØ§Ø¯: {', '.join(articles)}")
            
            # Content preview
            lines = chunk['content'].split('\n')[:3]
            for line in lines:
                if line.strip():
                    print(f"      {line.strip()[:80]}")
    else:
        print("   âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬")
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¯ÙŠÙ„Ø© - Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ù…Ø­ØªÙˆÙ‰
        print("\n   ğŸ” Ù…Ø­Ø§ÙˆÙ„Ø©: Ø¹Ø±Ø¶ Ø£ÙŠ Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ù†Ø¸Ø§Ù…...")
        params2 = {
            "select": "id,content,sequence_number",
            "source_id": f"eq.{SOURCE_ID}",
            "order": "sequence_number.asc",
            "limit": 3
        }
        response2 = requests.get(url, headers=get_headers(), params=params2)
        
        if response2.status_code == 200:
            any_chunks = response2.json()
            if any_chunks:
                print(f"   âœ… Ø¥Ø¬Ù…Ø§Ù„ÙŠ chunks ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…: Ù…ÙˆØ¬ÙˆØ¯Ø©")
                print(f"   ğŸ“„ Ø£ÙˆÙ„ chunk:")
                first = any_chunks[0]
                preview = first['content'][:300].replace('\n', ' ')
                print(f"      {preview}...")
else:
    print(f"   âŒ Ø®Ø·Ø£: {response.status_code}")
    print(f"   Response: {response.text[:500]}")

print("\n" + "=" * 70)
