"""
ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø§Ù„ØµØ­ÙŠØ­ Ø¹Ù† "Ø§Ù„Ù‡Ø¨Ø©" - Ù…Ø¹ country context
"""

import os
import requests
from dotenv import load_dotenv

load_dotenv()

# Supabase REST API
SUPABASE_REST_URL = "http://152.67.159.164:8000/rest/v1"
SUPABASE_ANON_KEY = os.getenv("SUPABASE_ANON_KEY", "")

# Lawyer ID Ù„Ù„Ù…Ø­Ø§Ù…ÙŠ Ø§Ù„Ø­Ø§Ù„ÙŠ
LAWYER_ID = "4e22ac65-9024-42f9-9b94-dc4980c51ad6"

def get_headers():
    """Headers Ù„Ù„Ù€ REST API"""
    return {
        "apikey": SUPABASE_ANON_KEY,
        "Authorization": f"Bearer {SUPABASE_ANON_KEY}",
        "Content-Type": "application/json"
    }

def search_hiba_correct():
    """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† 'Ø§Ù„Ù‡Ø¨Ø©' Ù…Ø¹ country_id Ø§Ù„ØµØ­ÙŠØ­"""
    
    print("=" * 60)
    print("ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† 'Ø§Ù„Ù‡Ø¨Ø©' (Ù…Ø¹ country context)")
    print("=" * 60)
    
    # 1. Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ country_id Ù„Ù„Ù…Ø­Ø§Ù…ÙŠ
    print("\n1ï¸âƒ£ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ country Ø§Ù„Ù…Ø­Ø§Ù…ÙŠ...")
    try:
        url = f"{SUPABASE_REST_URL}/users"
        params = {
            "select": "id,country_id",
            "id": f"eq.{LAWYER_ID}",
            "limit": 1
        }
        
        response = requests.get(url, headers=get_headers(), params=params)
        
        if response.status_code == 200 and response.json():
            user = response.json()[0]
            country_id = user.get('country_id')
            print(f"   âœ… Country ID: {country_id}")
        else:
            print(f"   âŒ Ø®Ø·Ø£: {response.status_code}")
            print("   âš ï¸ Ø³Ø£Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨Ø­Ø« Ø¨Ø¯ÙˆÙ† country filter...")
            country_id = None
    
    except Exception as e:
        print(f"   âŒ Ø®Ø·Ø£: {e}")
        country_id = None
    
    # 2. Ø¨Ø­Ø« Ø¹Ù† Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø¯Ù†ÙŠØ©
    print("\n2ï¸âƒ£ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø¯Ù†ÙŠØ©...")
    try:
        url = f"{SUPABASE_REST_URL}/legal_sources"
        params = {
            "select": "id,title,country_id",
            "title": "ilike.%Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø¯Ù†ÙŠØ©%",
            "limit": 5
        }
        
        # Ø£Ø¶Ù country filter Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        if country_id:
            params["country_id"] = f"eq.{country_id}"
        
        response = requests.get(url, headers=get_headers(), params=params)
        
        if response.status_code == 200 and response.json():
            sources = response.json()
            print(f"   âœ… ÙˆØ¬Ø¯Øª {len(sources)} Ù†Ø¸Ø§Ù…:")
            
            for idx, src in enumerate(sources, 1):
                print(f"      {idx}. {src['title']}")
                print(f"         ID: {src['id']}")
                print(f"         Country: {src.get('country_id', 'N/A')}")
            
            # Ø§Ø³ØªØ®Ø¯Ù… Ø£ÙˆÙ„ Ù†Ø¸Ø§Ù…
            source = sources[0]
            source_id = source['id']
            print(f"\n   ğŸ¯ Ø§Ø®ØªÙŠØ§Ø±: {source['title']}")
        else:
            print(f"   âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø¸Ø§Ù…")
            return
    
    except Exception as e:
        print(f"   âŒ Ø®Ø·Ø£: {e}")
        return
    
    # 3. Ø¨Ø­Ø« Ø¹Ù† chunks ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ "Ø§Ù„Ù‡Ø¨Ø©"
    print("\n3ï¸âƒ£ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† chunks ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 'Ø§Ù„Ù‡Ø¨Ø©'...")
    try:
        url = f"{SUPABASE_REST_URL}/document_chunks"
        params = {
            "select": "id,content,sequence_number,ai_summary",
            "source_id": f"eq.{source_id}",
            "or": "(content.ilike.%Ø§Ù„Ù‡Ø¨Ø©%,content.ilike.%Ø§Ù„Ù‡Ø¨Ù‡%,ai_summary.ilike.%Ø§Ù„Ù‡Ø¨Ø©%)",
            "order": "sequence_number.asc",
            "limit": 10
        }
        
        response = requests.get(url, headers=get_headers(), params=params)
        
        if response.status_code == 200:
            chunks = response.json()
            print(f"   âœ… ÙˆØ¬Ø¯Øª {len(chunks)} Ù†ØªÙŠØ¬Ø©!")
            
            if chunks:
                print("\n   ğŸ“„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
                for i, chunk in enumerate(chunks, 1):
                    print(f"\n      {i}. Sequence: {chunk['sequence_number']}")
                    content_preview = chunk['content'][:250].replace('\n', ' ')
                    print(f"         Content: {content_preview}...")
                    
                    if chunk.get('ai_summary'):
                        summary_preview = chunk['ai_summary'][:100]
                        print(f"         Summary: {summary_preview}...")
            else:
                print("   âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 'Ø§Ù„Ù‡Ø¨Ø©' ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù†Ø¸Ø§Ù…")
        else:
            print(f"   âŒ Ø®Ø·Ø£: {response.status_code}")
    
    except Exception as e:
        print(f"   âŒ Ø®Ø·Ø£: {e}")
    
    # 4. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¯
    print("\n4ï¸âƒ£ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¯...")
    try:
        url = f"{SUPABASE_REST_URL}/document_chunks"
        params = {
            "select": "id,content,sequence_number",
            "source_id": f"eq.{source_id}",
            "content": "ilike.%Ø§Ù„Ù…Ø§Ø¯Ø©%Ø§Ù„Ù‡Ø¨Ø©%",
            "order": "sequence_number.asc",
            "limit": 5
        }
        
        response = requests.get(url, headers=get_headers(), params=params)
        
        if response.status_code == 200:
            chunks = response.json()
            if chunks:
                print(f"   âœ… ÙˆØ¬Ø¯Øª {len(chunks)} Ù…Ø§Ø¯Ø©:")
                for chunk in chunks:
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ù‚Ù… Ø§Ù„Ù…Ø§Ø¯Ø© Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
                    import re
                    matches = re.findall(r'Ø§Ù„Ù…Ø§Ø¯Ø©\s*(\d+)', chunk['content'])
                    if matches:
                        print(f"      Ø§Ù„Ù…Ø§Ø¯Ø© {matches[0]} (Seq: {chunk['sequence_number']})")
    
    except Exception as e:
        print(f"   âŒ Ø®Ø·Ø£: {e}")
    
    print("\n" + "=" * 60)
    print("âœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø¨Ø­Ø«")
    print("=" * 60)

if __name__ == "__main__":
    search_hiba_correct()
