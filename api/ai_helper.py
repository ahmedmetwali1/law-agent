"""
AI Helper Endpoints
Endpoints for AI question generation and response analysis
"""

from fastapi import APIRouter
import requests
import logging

router = APIRouter()
logger = logging.getLogger(__name__)

LLM_URL = "http://152.67.159.164:3000/api/chat/completions"


@router.post("/generate-question")
async def generate_question(request: dict):
    """Generate intelligent question using AI"""
    try:
        case_facts = request.get("case_facts", "")
        conversation_history = request.get("conversation_history", [])
        
        # Build context
        conversation_summary = "\n".join([
            f"Ù…Ø³ØªØ®Ø¯Ù…: {turn.get('user', '')}\nÙ…Ø­Ø§Ù…ÙŠ: {turn.get('lawyer', '')}"
            for turn in conversation_history[-3:]
        ])
        
        prompt = f"""Ø£Ù†Øª Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ø§Ø¯ÙŠ ØªØ¨Ø­Ø« Ø¹Ù† Ù…Ø³Ø§Ø¹Ø¯Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ÙÙŠ Ù‚Ø¶ÙŠØ© Ø£Ø­ÙˆØ§Ù„ Ø´Ø®ØµÙŠØ©.

ÙˆÙ‚Ø§Ø¦Ø¹ Ù‚Ø¶ÙŠØªÙƒ:
{case_facts}

Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†:
{conversation_summary if conversation_summary else 'Ù„Ù… ØªØ¨Ø¯Ø£ Ø¨Ø¹Ø¯'}

Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø³Ù„ÙˆÙƒ:
1. ØªØ­Ø¯Ø« Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ ÙƒÙ…Ø³ØªØ®Ø¯Ù… Ø¹Ø§Ø¯ÙŠ (Ù„ÙŠØ³ Ù…Ø­Ø§Ù…Ù)
2. Ø£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø­Ø§Ù…ÙŠ Ø¨ÙˆØ¶ÙˆØ­ ÙˆØ¨Ø³Ø§Ø·Ø©
3. Ø¥Ø°Ø§ Ø³Ø£Ù„Ùƒ Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù„ÙŠØ³Øª ÙÙŠ Ø§Ù„ÙˆÙ‚Ø§Ø¦Ø¹ØŒ Ù‚Ù„ "Ù„Ø§ Ø£Ø¹Ù„Ù…"
4. Ø§Ø³Ø£Ù„ Ø£Ø³Ø¦Ù„Ø© Ù…Ù†Ø·Ù‚ÙŠØ© ØªØªØ¹Ù„Ù‚ Ø¨Ø­Ù‚ÙˆÙ‚Ùƒ ÙƒØ£Ø¨
5. Ù„Ø§ ØªØ¹Ø·Ù ÙƒÙ„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©

Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ/Ø±Ø¯Ùƒ Ø§Ù„ØªØ§Ù„ÙŠ ÙÙ‚Ø· (Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø© Ø£Ùˆ Ø¬Ù…Ù„ØªÙŠÙ†)
Ù„Ø§ ØªÙƒØªØ¨ Ø´Ø±Ø­ØŒ ÙÙ‚Ø· Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø±:"""

        # Call LLM
        response = requests.post(
            LLM_URL,
            json={
                "model": "gpt-oss-120b",
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.8,
                "max_tokens": 150
            },
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            question = data["choices"][0]["message"]["content"].strip()
            question = question.replace('"', '').replace("'", "").strip()
            return {"question": question}
        else:
            # Fallback to default questions
            defaults = [
                "Ù…Ø±Ø­Ø¨Ø§Ù‹ØŒ Ø£Ù†Ø§ Ø£Ø¨ ÙˆØ£Ø±ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©",
                "Ø£Ø­ÙˆØ§Ù„ Ø´Ø®ØµÙŠØ© Ø±Ø¤ÙŠØ© ØµØºØ§Ø±",
                "Ø£Ø±ÙŠØ¯ Ù…Ø¹Ø±ÙØ© Ø­Ù‚ÙˆÙ‚ÙŠ ÙÙŠ Ø±Ø¤ÙŠØ© Ø£Ø·ÙØ§Ù„ÙŠ",
                "ÙƒÙ… Ù…Ø±Ø© ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø±Ø¤ÙŠØ© Ø£Ø·ÙØ§Ù„ÙŠØŸ",
                "Ù…Ø§Ø°Ø§ Ø£ÙØ¹Ù„ Ø¥Ø°Ø§ Ù…Ù†Ø¹Øª Ø§Ù„Ø£Ù… Ø§Ù„Ø±Ø¤ÙŠØ©ØŸ",
                "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø·Ù„Ø¨ ØªØ¹Ø¯ÙŠÙ„ Ø­ÙƒÙ… Ø§Ù„Ø±Ø¤ÙŠØ©ØŸ"
            ]
            turn_index = len(conversation_history) % len(defaults)
            return {"question": defaults[turn_index]}
            
    except Exception as e:
        logger.error(f"Error generating question: {e}")
        return {"question": "Ø£Ø±ÙŠØ¯ Ø§Ø³ØªØ´Ø§Ø±Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¨Ø®ØµÙˆØµ Ø­Ù‚ÙˆÙ‚ÙŠ"}


@router.post("/analyze-response")
async def analyze_response(request: dict):
    """Analyze lawyer's response using AI"""
    try:
        lawyer_response = request.get("response", "")
        
        prompt = f"""Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ø®Ø¨ÙŠØ± Ù„Ø³Ù„ÙˆÙƒ ÙˆÙƒÙ„Ø§Ø¡ AI Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠÙŠÙ†.

Ø±Ø¯ Ø§Ù„Ù…Ø­Ø§Ù…ÙŠ:
{lawyer_response}

Ù‚ÙŠÙ‘Ù… Ø§Ù„Ø±Ø¯ Ù…Ù† 1 Ø¥Ù„Ù‰ 10:
1. Ø§Ù„ÙˆØ¯ÙŠØ© ÙˆØ§Ù„ØªØ¹Ø§Ø·Ù
2. Ø§Ù„ÙˆØ¶ÙˆØ­ ÙˆØ§Ù„ÙÙ‡Ù…
3. Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
4. Ø·Ø±Ø­ Ø£Ø³Ø¦Ù„Ø© Ù…ÙÙŠØ¯Ø©
5. Ø§Ù„ØªÙ‚Ø¯Ù… Ù†Ø­Ùˆ Ø§Ù„Ø­Ù„

Ø§ÙƒØªØ¨ ØªÙ‚ÙŠÙŠÙ…Ùƒ:
ÙˆØ¯ÙŠØ©: X/10
ÙˆØ¶ÙˆØ­: X/10
Ø¯Ù‚Ø©: X/10
Ø£Ø³Ø¦Ù„Ø©: X/10
ØªÙ‚Ø¯Ù…: X/10
Ù…Ù„Ø§Ø­Ø¸Ø©: [Ù‚ØµÙŠØ±Ø©]"""

        response = requests.post(
            LLM_URL,
            json={
                "model": "gpt-oss-120b",
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3,
                "max_tokens": 200
            },
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            analysis = data["choices"][0]["message"]["content"].strip()
            return {"analysis": analysis}
        else:
            return {"analysis": "ØªØ­Ù„ÙŠÙ„ ØºÙŠØ± Ù…ØªØ§Ø­"}
            
    except Exception as e:
        logger.error(f"Error analyzing response: {e}")
        return {"analysis": f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„"}


@router.post("/chat")
async def chat_endpoint(request: dict):
    """
    AI Chat endpoint for ChatPage
    Accepts: { message: str, session_id: str, generate_title: bool, lawyer_id: str }
    Returns: { message: str, suggested_title: str? }
    
    Security: Input validation, message length limits, XSS prevention
    """
    try:
        from agents.core.enhanced_general_lawyer_agent import EnhancedGeneralLawyerAgent
        from agents.storage.user_storage import user_storage
        from api.utils.security import validate_message_content, validate_lawyer_id
        
        message = request.get("message", "")
        session_id = request.get("session_id")
        generate_title = request.get("generate_title", False)
        lawyer_id = request.get("lawyer_id")
        
        # âœ… Security: Validate inputs
        validate_message_content(message)
        validate_lawyer_id(lawyer_id)
        
        logger.info(f"ğŸ’¬ Chat request from lawyer {lawyer_id}: {message[:50]}...")
        
        # Get user context like /api/chat does
        agent = None
        
        if lawyer_id:
            # Get the current user details
            current_user = user_storage.get_user_by_id(lawyer_id)
            
            if current_user:
                current_user.pop("password_hash", None)
                
                # Determine who the "Office Owner" (Lawyer) is
                if current_user.get("office_id"):
                    # This is an ASSISTANT
                    target_lawyer_id = current_user.get("office_id")
                    agent = EnhancedGeneralLawyerAgent(
                        lawyer_id=target_lawyer_id,
                        lawyer_name=None,
                        current_user=current_user
                    )
                else:
                    # This is the LAWYER
                    target_lawyer_id = lawyer_id
                    agent = EnhancedGeneralLawyerAgent(
                        lawyer_id=target_lawyer_id,
                        lawyer_name=None,
                        current_user=current_user
                    )
            else:
                # Fallback to global agent
                from api.main import general_agent
                agent = general_agent
        else:
            # No lawyer_id - use global agent
            from api.main import general_agent
            agent = general_agent
        
        # Process message
        response = agent.process_user_message(message)
        
        # Extract text from response
        if isinstance(response, dict):
            ai_message = response.get("response", response.get("message", str(response)))
        else:
            ai_message = str(response)
        
        # âœ… Security: Validate AI response length
        if len(ai_message) > 50000:
            logger.warning(f"AI response too long: {len(ai_message)} chars, truncating")
            ai_message = ai_message[:50000] + "..."
        
        result = {"message": ai_message}
        
        # Generate title if first message
        if generate_title:
            title_prompt = f"Ø§Ù‚ØªØ±Ø­ Ø¹Ù†ÙˆØ§Ù†Ø§Ù‹ Ù‚ØµÙŠØ±Ø§Ù‹ (3-5 ÙƒÙ„Ù…Ø§Øª) Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©:\nØ§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {message}\nØ§Ù„Ù…Ø³Ø§Ø¹Ø¯: {ai_message[:100]}"
            
            try:
                title_response = requests.post(
                    LLM_URL,
                    json={
                        "model": "gpt-oss-120b",
                        "messages": [{"role": "user", "content": title_prompt}],
                        "temperature": 0.7,
                        "max_tokens": 20
                    },
                    timeout=10
                )
                
                if title_response.status_code == 200:
                    title_data = title_response.json()
                    suggested_title = title_data["choices"][0]["message"]["content"].strip().replace('"', '')
                    # âœ… Security: Validate title length
                    if len(suggested_title) > 100:
                        suggested_title = suggested_title[:100]
                    result["suggested_title"] = suggested_title
            except Exception as e:
                logger.warning(f"Title generation failed: {e}")
                pass  # Title generation is optional
        
        logger.info(f"âœ… Chat response generated for lawyer {lawyer_id}")
        return result
        
    except HTTPException:
        raise  # Re-raise HTTP exceptions (validation errors)
    except Exception as e:
        logger.error(f"âŒ Chat error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³Ø§Ù„Ø©")
