"""
Advanced Deep Thinking Tool v2.0
Ø£Ø¯Ø§Ø© Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©

Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª:
1. Ø¯Ù…Ø¬ Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ø±Ù…Ø²ÙŠ (PSL)
2. Ø°Ø§ÙƒØ±Ø© Ø·ÙˆÙŠÙ„Ø© Ø§Ù„Ù…Ø¯Ù‰
3. ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£ÙÙƒØ§Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
4. ÙƒØ´Ù ØªÙ†Ø§Ù‚Ø¶Ø§Øª Ù…Ù†Ø·Ù‚ÙŠ
5. ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©
6. Ù…Ø¹Ø§Ù„Ø¬Ø© JSON Ù…Ø­Ø³Ù‘Ù†Ø©
7. Caching Ø°ÙƒÙŠ
8. ØªØªØ¨Ø¹ Ø³Ù„Ø³Ù„Ø© Ø§Ù„ØªÙÙƒÙŠØ±
"""

import time
import json
import hashlib
import logging
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime
from collections import defaultdict
import numpy as np

from .base_tool import BaseTool, ToolResult

logger = logging.getLogger(__name__)


# ============================================================
# ENUMS & DATA STRUCTURES
# ============================================================

class ThinkingMode(Enum):
    """Ø£ÙˆØ¶Ø§Ø¹ Ø§Ù„ØªÙÙƒÙŠØ±"""
    DECOMPOSE = "decompose"
    HYPOTHESIZE = "hypothesize"
    SIMULATE = "simulate"
    BRAINSTORM = "brainstorm"
    CONTRADICTIONS = "contradictions"
    PERSPECTIVES = "perspectives"
    CHALLENGE = "challenge"
    ANALOGICAL = "analogical"      # Ø¬Ø¯ÙŠØ¯: Ø§Ù„Ù‚ÙŠØ§Ø³
    CAUSAL = "causal"              # Ø¬Ø¯ÙŠØ¯: Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¨Ø¨ÙŠ
    TEMPORAL = "temporal"          # Ø¬Ø¯ÙŠØ¯: Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ
    FULL = "full"


class IdeaCategory(Enum):
    """ØªØµÙ†ÙŠÙ Ø§Ù„Ø£ÙÙƒØ§Ø±"""
    LEGAL = "legal"
    PROCEDURAL = "procedural"
    CREATIVE = "creative"
    UNCONVENTIONAL = "unconventional"
    RISKY = "risky"


class ContradictionType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªÙ†Ø§Ù‚Ø¶Ø§Øª"""
    DIRECT = "direct"          # ØªÙ†Ø§Ù‚Ø¶ Ù…Ø¨Ø§Ø´Ø± ØµØ±ÙŠØ­
    IMPLICIT = "implicit"      # ØªÙ†Ø§Ù‚Ø¶ Ø¶Ù…Ù†ÙŠ
    APPARENT = "apparent"      # ØªÙ†Ø§Ù‚Ø¶ Ø¸Ø§Ù‡Ø±ÙŠ Ù‚Ø§Ø¨Ù„ Ù„Ù„Ø­Ù„
    TEMPORAL = "temporal"      # ØªÙ†Ø§Ù‚Ø¶ Ø²Ù…Ù†ÙŠ (ÙƒØ§Ù† ØµØ­ÙŠØ­Ø§Ù‹ Ø«Ù… ØªØºÙŠØ±)


@dataclass
class Viewpoint:
    """ÙˆØ¬Ù‡Ø© Ù†Ø¸Ø± Ù…Ø­Ø³Ù‘Ù†Ø©"""
    perspective: str
    position: str
    arguments: List[str]
    weaknesses: List[str]
    confidence: float = 0.7
    sources: List[str] = field(default_factory=list)
    
    def strength_score(self) -> float:
        """Ø­Ø³Ø§Ø¨ Ù‚ÙˆØ© ÙˆØ¬Ù‡Ø© Ø§Ù„Ù†Ø¸Ø±"""
        arg_score = min(1.0, len(self.arguments) / 3)
        weak_penalty = min(0.5, len(self.weaknesses) * 0.1)
        return (arg_score - weak_penalty) * self.confidence


@dataclass
class Contradiction:
    """ØªÙ†Ø§Ù‚Ø¶ Ù…Ø­Ø³Ù‘Ù†"""
    item1: str
    item2: str
    contradiction_type: ContradictionType
    explanation: str
    severity: float  # 0-1
    resolution_suggestion: Optional[str] = None
    is_resolved: bool = False
    
    def to_dict(self) -> Dict:
        return {
            "item1": self.item1,
            "item2": self.item2,
            "type": self.contradiction_type.value,
            "explanation": self.explanation,
            "severity": self.severity,
            "resolution": self.resolution_suggestion,
            "resolved": self.is_resolved
        }


@dataclass
class Idea:
    """ÙÙƒØ±Ø© Ù…Ø¹ ØªÙ‚ÙŠÙŠÙ…"""
    content: str
    category: IdeaCategory
    potential: float  # 0-1
    feasibility: float  # 0-1
    risk: float  # 0-1
    source_ideas: List[str] = field(default_factory=list)  # Ø§Ù„Ø£ÙÙƒØ§Ø± Ø§Ù„Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„ÙŠÙ‡Ø§
    
    @property
    def score(self) -> float:
        """Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„ÙÙƒØ±Ø©"""
        return (self.potential * 0.4 + self.feasibility * 0.4 - self.risk * 0.2)


@dataclass
class ThinkingStep:
    """Ø®Ø·ÙˆØ© ÙÙŠ Ø§Ù„ØªÙÙƒÙŠØ±"""
    step_id: int
    mode: ThinkingMode
    input_summary: str
    output_summary: str
    confidence: float
    duration_ms: float
    insights: List[str] = field(default_factory=list)


@dataclass
class ThinkingSession:
    """Ø¬Ù„Ø³Ø© ØªÙÙƒÙŠØ± ÙƒØ§Ù…Ù„Ø©"""
    session_id: str
    question: str
    context: str
    steps: List[ThinkingStep] = field(default_factory=list)
    ideas: List[Idea] = field(default_factory=list)
    contradictions: List[Contradiction] = field(default_factory=list)
    viewpoints: List[Viewpoint] = field(default_factory=list)
    final_insights: List[str] = field(default_factory=list)
    confidence: float = 0.0
    start_time: datetime = field(default_factory=datetime.now)
    
    def add_step(self, step: ThinkingStep):
        self.steps.append(step)
    
    def get_summary(self) -> Dict:
        return {
            "session_id": self.session_id,
            "question": self.question[:100],
            "steps_count": len(self.steps),
            "ideas_count": len(self.ideas),
            "contradictions_count": len(self.contradictions),
            "viewpoints_count": len(self.viewpoints),
            "confidence": self.confidence,
            "duration_ms": sum(s.duration_ms for s in self.steps)
        }


# ============================================================
# CACHING & MEMORY
# ============================================================

class ThinkingMemory:
    """Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚"""
    
    def __init__(self, max_sessions: int = 100):
        self.sessions: Dict[str, ThinkingSession] = {}
        self.idea_bank: List[Idea] = []  # Ø¨Ù†Ùƒ Ø§Ù„Ø£ÙÙƒØ§Ø±
        self.contradiction_patterns: List[Contradiction] = []  # Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªÙ†Ø§Ù‚Ø¶Ø§Øª
        self.max_sessions = max_sessions
    
    def store_session(self, session: ThinkingSession):
        """Ø­ÙØ¸ Ø¬Ù„Ø³Ø©"""
        if len(self.sessions) >= self.max_sessions:
            oldest = min(self.sessions.values(), key=lambda s: s.start_time)
            del self.sessions[oldest.session_id]
        
        self.sessions[session.session_id] = session
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£ÙÙƒØ§Ø± Ø§Ù„Ø¬ÙŠØ¯Ø© Ù„Ù„Ø¨Ù†Ùƒ
        for idea in session.ideas:
            if idea.score > 0.7:
                self.idea_bank.append(idea)
        
        # Ø­ÙØ¸ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªÙ†Ø§Ù‚Ø¶Ø§Øª
        self.contradiction_patterns.extend(session.contradictions)
    
    def find_similar_session(self, question: str) -> Optional[ThinkingSession]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù„Ø³Ø© Ù…Ø´Ø§Ø¨Ù‡Ø©"""
        # Ø¨Ø­Ø« Ø¨Ø³ÙŠØ· Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©
        question_words = set(question.split())
        
        best_match = None
        best_score = 0
        
        for session in self.sessions.values():
            session_words = set(session.question.split())
            overlap = len(question_words & session_words)
            score = overlap / max(len(question_words), len(session_words))
            
            if score > best_score and score > 0.5:
                best_score = score
                best_match = session
        
        return best_match
    
    def get_relevant_ideas(self, context: str, top_k: int = 5) -> List[Idea]:
        """Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø£ÙÙƒØ§Ø± Ø°Ø§Øª ØµÙ„Ø©"""
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø·
        sorted_ideas = sorted(self.idea_bank, key=lambda i: i.score, reverse=True)
        return sorted_ideas[:top_k]


class ThinkingCache:
    """ÙƒØ§Ø´ Ù„Ù„ØªÙÙƒÙŠØ±"""
    
    def __init__(self, max_size: int = 500):
        self.cache: Dict[str, Tuple[Dict, datetime]] = {}
        self.max_size = max_size
        self.ttl_hours = 24
    
    def _hash(self, question: str, mode: str, context: str) -> str:
        key = f"{question}|{mode}|{context[:200]}"
        return hashlib.md5(key.encode()).hexdigest()
    
    def get(self, question: str, mode: str, context: str = "") -> Optional[Dict]:
        key = self._hash(question, mode, context)
        if key in self.cache:
            result, timestamp = self.cache[key]
            age = (datetime.now() - timestamp).total_seconds() / 3600
            if age < self.ttl_hours:
                return result
            del self.cache[key]
        return None
    
    def set(self, question: str, mode: str, context: str, result: Dict):
        if len(self.cache) >= self.max_size:
            oldest = min(self.cache, key=lambda k: self.cache[k][1])
            del self.cache[oldest]
        
        key = self._hash(question, mode, context)
        self.cache[key] = (result, datetime.now())


# ============================================================
# LOGICAL CONTRADICTION DETECTOR
# ============================================================

class LogicalContradictionDetector:
    """ÙƒØ§Ø´Ù Ø§Ù„ØªÙ†Ø§Ù‚Ø¶Ø§Øª Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ"""
    
    def __init__(self):
        # Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªÙ†Ø§Ù‚Ø¶ Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©
        self.contradiction_patterns = [
            # (Ù†Ù…Ø· 1ØŒ Ù†Ù…Ø· 2ØŒ Ù†ÙˆØ¹ Ø§Ù„ØªÙ†Ø§Ù‚Ø¶)
            (r"ÙŠØ¬ÙˆØ²", r"Ù„Ø§ ÙŠØ¬ÙˆØ²", ContradictionType.DIRECT),
            (r"ÙŠØ¬Ø¨", r"Ù„Ø§ ÙŠØ¬Ø¨", ContradictionType.DIRECT),
            (r"ØµØ­ÙŠØ­", r"Ø¨Ø§Ø·Ù„", ContradictionType.DIRECT),
            (r"(\d+) ÙŠÙˆÙ…", r"(\d+) ÙŠÙˆÙ…", ContradictionType.APPARENT),  # Ø£Ø±Ù‚Ø§Ù… Ù…Ø®ØªÙ„ÙØ©
        ]
    
    def detect(self, items: List[Dict]) -> List[Contradiction]:
        """ÙƒØ´Ù Ø§Ù„ØªÙ†Ø§Ù‚Ø¶Ø§Øª ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"""
        contradictions = []
        
        for i, item1 in enumerate(items):
            content1 = item1.get("content", str(item1))
            
            for item2 in items[i+1:]:
                content2 = item2.get("content", str(item2))
                
                # ÙØ­Øµ Ø§Ù„ØªÙ†Ø§Ù‚Ø¶Ø§Øª Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©
                for pattern1, pattern2, ctype in self.contradiction_patterns:
                    if self._matches(content1, pattern1) and self._matches(content2, pattern2):
                        contradictions.append(Contradiction(
                            item1=content1[:200],
                            item2=content2[:200],
                            contradiction_type=ctype,
                            explanation=f"ØªÙ†Ø§Ù‚Ø¶ Ù…Ø­ØªÙ…Ù„ Ø¨ÙŠÙ† '{pattern1}' Ùˆ '{pattern2}'",
                            severity=0.7 if ctype == ContradictionType.DIRECT else 0.4
                        ))
                
                # ÙØ­Øµ Ø§Ù„ØªÙ†Ø§Ù‚Ø¶Ø§Øª Ø§Ù„Ø¹Ø¯Ø¯ÙŠØ©
                num_contradiction = self._check_numerical_contradiction(content1, content2)
                if num_contradiction:
                    contradictions.append(num_contradiction)
        
        return contradictions
    
    def _matches(self, text: str, pattern: str) -> bool:
        """ÙØ­Øµ ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù†Ù…Ø·"""
        import re
        return bool(re.search(pattern, text))
    
    def _check_numerical_contradiction(self, text1: str, text2: str) -> Optional[Contradiction]:
        """ÙØ­Øµ Ø§Ù„ØªÙ†Ø§Ù‚Ø¶Ø§Øª Ø§Ù„Ø¹Ø¯Ø¯ÙŠØ©"""
        import re
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ù…Ø¹ Ø³ÙŠØ§Ù‚Ù‡Ø§
        pattern = r'(\d+)\s*(ÙŠÙˆÙ…|Ø´Ù‡Ø±|Ø³Ù†Ø©|Ø±ÙŠØ§Ù„|Ùª)'
        
        matches1 = re.findall(pattern, text1)
        matches2 = re.findall(pattern, text2)
        
        for num1, unit1 in matches1:
            for num2, unit2 in matches2:
                if unit1 == unit2 and num1 != num2:
                    return Contradiction(
                        item1=f"{num1} {unit1}",
                        item2=f"{num2} {unit2}",
                        contradiction_type=ContradictionType.APPARENT,
                        explanation=f"Ø§Ø®ØªÙ„Ø§Ù ÙÙŠ Ø§Ù„Ù‚ÙŠÙ…Ø©: {num1} vs {num2} {unit1}",
                        severity=0.5,
                        resolution_suggestion="ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ - Ù‚Ø¯ ØªÙƒÙˆÙ† Ù„Ø­Ø§Ù„Ø§Øª Ù…Ø®ØªÙ„ÙØ©"
                    )
        
        return None


# ============================================================
# IDEA EVALUATOR
# ============================================================

class IdeaEvaluator:
    """Ù…Ù‚ÙŠÙ‘Ù… Ø§Ù„Ø£ÙÙƒØ§Ø±"""
    
    def __init__(self):
        # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
        self.feasibility_keywords = {
            "high": ["Ù…Ù…ÙƒÙ†", "Ø³Ù‡Ù„", "Ù…Ø¨Ø§Ø´Ø±", "ÙˆØ§Ø¶Ø­"],
            "low": ["ØµØ¹Ø¨", "Ù…Ø¹Ù‚Ø¯", "Ù†Ø§Ø¯Ø±", "Ù…Ø³ØªØ­ÙŠÙ„"]
        }
        
        self.risk_keywords = {
            "high": ["Ø®Ø·Ø±", "ØºØ±Ø§Ù…Ø©", "Ø¹Ù‚ÙˆØ¨Ø©", "Ø±ÙØ¶"],
            "low": ["Ø¢Ù…Ù†", "Ù…Ø¶Ù…ÙˆÙ†", "Ù…Ø¤ÙƒØ¯"]
        }
    
    def evaluate(self, idea_text: str, context: str = "") -> Idea:
        """ØªÙ‚ÙŠÙŠÙ… ÙÙƒØ±Ø©"""
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙØ¦Ø©
        category = self._categorize(idea_text)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¬Ø¯ÙˆÙ‰
        feasibility = self._calculate_feasibility(idea_text)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø®Ø§Ø·Ø±
        risk = self._calculate_risk(idea_text)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ù…ÙƒØ§Ù†ÙŠØ©
        potential = self._calculate_potential(idea_text, context)
        
        return Idea(
            content=idea_text,
            category=category,
            potential=potential,
            feasibility=feasibility,
            risk=risk
        )
    
    def _categorize(self, text: str) -> IdeaCategory:
        """ØªØµÙ†ÙŠÙ Ø§Ù„ÙÙƒØ±Ø©"""
        legal_keywords = ["Ø¯Ø¹ÙˆÙ‰", "Ù…Ø­ÙƒÙ…Ø©", "Ù‚Ø§Ù†ÙˆÙ†", "Ù…Ø§Ø¯Ø©", "Ù†Ø¸Ø§Ù…"]
        procedural_keywords = ["Ø¥Ø¬Ø±Ø§Ø¡", "Ø®Ø·ÙˆØ©", "ØªÙ‚Ø¯ÙŠÙ…", "Ø±ÙØ¹"]
        creative_keywords = ["Ø¨Ø¯ÙŠÙ„", "Ø¬Ø¯ÙŠØ¯", "Ù…Ø¨ØªÙƒØ±"]
        
        if any(kw in text for kw in legal_keywords):
            return IdeaCategory.LEGAL
        elif any(kw in text for kw in procedural_keywords):
            return IdeaCategory.PROCEDURAL
        elif any(kw in text for kw in creative_keywords):
            return IdeaCategory.CREATIVE
        else:
            return IdeaCategory.UNCONVENTIONAL
    
    def _calculate_feasibility(self, text: str) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¬Ø¯ÙˆÙ‰"""
        score = 0.5
        
        for kw in self.feasibility_keywords["high"]:
            if kw in text:
                score += 0.1
        
        for kw in self.feasibility_keywords["low"]:
            if kw in text:
                score -= 0.1
        
        return max(0.0, min(1.0, score))
    
    def _calculate_risk(self, text: str) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø®Ø§Ø·Ø±"""
        score = 0.3
        
        for kw in self.risk_keywords["high"]:
            if kw in text:
                score += 0.15
        
        for kw in self.risk_keywords["low"]:
            if kw in text:
                score -= 0.1
        
        return max(0.0, min(1.0, score))
    
    def _calculate_potential(self, text: str, context: str) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ù…ÙƒØ§Ù†ÙŠØ©"""
        # ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ·
        base_score = 0.5
        
        # Ø²ÙŠØ§Ø¯Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ÙÙƒØ±Ø© Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø§Ù„Ø³ÙŠØ§Ù‚
        context_words = set(context.split())
        idea_words = set(text.split())
        overlap = len(context_words & idea_words)
        
        relevance_bonus = min(0.3, overlap * 0.05)
        
        return min(1.0, base_score + relevance_bonus)


# ============================================================
# ENHANCED DEEP THINKING TOOL
# ============================================================

class EnhancedDeepThinkingTool(BaseTool):
    """
    Ø£Ø¯Ø§Ø© Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
    
    Features:
    1. All original modes + 3 new ones
    2. Logical contradiction detection
    3. Idea evaluation & ranking
    4. Session memory
    5. Caching
    6. Thinking trace
    7. Multi-step reasoning
    """
    
    def __init__(self, llm_client=None):
        super().__init__(
            name="enhanced_deep_thinking",
            description="ØªÙÙƒÙŠØ± Ø¹Ù…ÙŠÙ‚ Ù…ØªÙ‚Ø¯Ù… Ù…Ø¹ ÙƒØ´Ù ØªÙ†Ø§Ù‚Ø¶Ø§Øª Ù…Ù†Ø·Ù‚ÙŠ ÙˆØªÙ‚ÙŠÙŠÙ… Ø£ÙÙƒØ§Ø±"
        )
        self.llm_client = llm_client
        self.memory = ThinkingMemory()
        self.cache = ThinkingCache()
        self.contradiction_detector = LogicalContradictionDetector()
        self.idea_evaluator = IdeaEvaluator()
        
        self.current_session: Optional[ThinkingSession] = None
    
    def run(
        self,
        question: str,
        context: str = "",
        mode: str = "full",
        gathered_info: Optional[List[Dict]] = None,
        previous_conclusions: Optional[List[str]] = None,
        use_cache: bool = True,
        use_memory: bool = True
    ) -> ToolResult:
        """
        ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚
        """
        self._track_usage()
        start_time = time.time()
        
        try:
            # Check for trivial queries (Quick Exit)
            if len(question.strip().split()) < 3 and mode != "simulate":
                return ToolResult(
                    success=True,
                    data={"response": "Question too short for deep thinking", "recommendation": "Use direct chat"},
                    metadata={"skipped": True},
                    execution_time_ms=0
                )

            logger.info(f"ğŸ§  EnhancedDeepThinking ({mode}): '{question[:50]}...'")
            
            # ÙØ­Øµ Ø§Ù„ÙƒØ§Ø´
            if use_cache:
                cached = self.cache.get(question, mode, context)
                if cached:
                    logger.info("âš¡ Cache hit")
                    return ToolResult(
                        success=True,
                        data=cached,
                        metadata={"cache_hit": True, "mode": mode},
                        execution_time_ms=(time.time() - start_time) * 1000
                    )
            
            # ÙØ­Øµ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            if use_memory:
                similar = self.memory.find_similar_session(question)
                if similar:
                    logger.info(f"ğŸ’­ Found similar session: {similar.session_id}")
            
            # Ø¨Ø¯Ø¡ Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø©
            session_id = hashlib.md5(f"{question}{time.time()}".encode()).hexdigest()[:10]
            self.current_session = ThinkingSession(
                session_id=session_id,
                question=question,
                context=context
            )
            
            # ØªÙ†ÙÙŠØ° Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
            mode_enum = ThinkingMode(mode) if mode in [m.value for m in ThinkingMode] else ThinkingMode.FULL
            
            result = self._execute_mode(
                mode=mode_enum,
                question=question,
                context=context,
                gathered_info=gathered_info or [],
                previous_conclusions=previous_conclusions or []
            )
            
            # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´ ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø©
            if use_cache:
                self.cache.set(question, mode, context, result)
            
            if use_memory:
                self.memory.store_session(self.current_session)
            
            elapsed = (time.time() - start_time) * 1000
            
            return ToolResult(
                success=True,
                data=result,
                metadata={
                    "mode": mode,
                    "session_id": session_id,
                    "steps_count": len(self.current_session.steps),
                    "ideas_count": len(self.current_session.ideas),
                    "contradictions_found": len(self.current_session.contradictions),
                    "cache_hit": False
                },
                execution_time_ms=elapsed
            )
            
        except Exception as e:
            logger.error(f"âŒ EnhancedDeepThinking failed: {e}")
            return ToolResult(
                success=False,
                error=str(e),
                metadata={"mode": mode},
                execution_time_ms=(time.time() - start_time) * 1000
            )
    
    def _execute_mode(
        self,
        mode: ThinkingMode,
        question: str,
        context: str,
        gathered_info: List[Dict],
        previous_conclusions: List[str]
    ) -> Dict[str, Any]:
        """ØªÙ†ÙÙŠØ° Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø­Ø¯Ø¯"""
        
        mode_handlers = {
            ThinkingMode.DECOMPOSE: self._decompose,
            ThinkingMode.HYPOTHESIZE: self._hypothesize,
            ThinkingMode.SIMULATE: self._simulate,
            ThinkingMode.BRAINSTORM: self._brainstorm_enhanced,
            ThinkingMode.CONTRADICTIONS: self._find_contradictions_enhanced,
            ThinkingMode.PERSPECTIVES: self._multi_perspective,
            ThinkingMode.CHALLENGE: self._challenge_assumptions,
            ThinkingMode.ANALOGICAL: self._analogical_reasoning,
            ThinkingMode.CAUSAL: self._causal_analysis,
            ThinkingMode.TEMPORAL: self._temporal_analysis,
            ThinkingMode.FULL: self._full_analysis_enhanced
        }
        
        handler = mode_handlers.get(mode, self._full_analysis_enhanced)
        
        step_start = time.time()
        result = handler(question, context, gathered_info, previous_conclusions)
        step_duration = (time.time() - step_start) * 1000
        
        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø·ÙˆØ©
        self.current_session.add_step(ThinkingStep(
            step_id=len(self.current_session.steps) + 1,
            mode=mode,
            input_summary=question[:100],
            output_summary=str(result)[:200],
            confidence=result.get("confidence", 0.7),
            duration_ms=step_duration,
            insights=result.get("key_insights", [])
        ))
        
        return result
    
    def _decompose(self, question, context, gathered_info, conclusions) -> Dict:
        """ØªÙÙƒÙŠÙƒ Ø§Ù„Ø³Ø¤Ø§Ù„"""
        prompt = f"""Ø­Ù„Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆÙ‚Ø³Ù…Ù‡ Ø¥Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© ÙØ±Ø¹ÙŠØ©:

Ø§Ù„Ø³Ø¤Ø§Ù„: {question}
Ø§Ù„Ø³ÙŠØ§Ù‚: {context if context else "Ù„Ø§ ÙŠÙˆØ¬Ø¯"}

Ø£Ø¬Ø¨ Ø¨Ù€ JSON:
{{
  "main_question": "...",
  "sub_questions": [
    {{"question": "...", "category": "ÙˆÙ‚Ø§Ø¦Ø¹/Ù‚Ø§Ù†ÙˆÙ†/Ø¥Ø¬Ø±Ø§Ø¡", "priority": "high/medium/low", "depends_on": []}}
  ],
  "missing_info": ["..."],
  "search_keywords": ["..."],
  "complexity_score": 5
}}"""
        return self._call_llm_json(prompt)
    
    def _hypothesize(self, question, context, gathered_info, conclusions) -> Dict:
        """ØªÙˆÙ„ÙŠØ¯ ÙØ±Ø¶ÙŠØ§Øª"""
        prompt = f"""ÙˆÙ„Ù‘Ø¯ ÙØ±Ø¶ÙŠØ§Øª Ù„Ù„Ù‚Ø¶ÙŠØ©:

Ø§Ù„Ù‚Ø¶ÙŠØ©: {question}
Ø§Ù„Ø³ÙŠØ§Ù‚: {context if context else "Ù„Ø§ ÙŠÙˆØ¬Ø¯"}

Ø£Ø¬Ø¨ Ø¨Ù€ JSON:
{{
  "hypotheses": [
    {{
      "id": "H1",
      "statement": "...",
      "probability": 0.7,
      "supporting_evidence": ["..."],
      "contradicting_evidence": ["..."],
      "test_method": "..."
    }}
  ],
  "most_likely": "H1",
  "reasoning": "..."
}}"""
        return self._call_llm_json(prompt)
    
    def _simulate(self, question, context, gathered_info, conclusions) -> Dict:
        """Ù…Ø­Ø§ÙƒØ§Ø© Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª"""
        prompt = f"""Ø¶Ø¹ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ù…Ø®ØªÙ„ÙØ©:

Ø§Ù„Ù‚Ø¶ÙŠØ©: {question}
Ø§Ù„ÙˆÙ‚Ø§Ø¦Ø¹: {context if context else "Ù„Ø§ ÙŠÙˆØ¬Ø¯"}

Ø£Ø¬Ø¨ Ø¨Ù€ JSON:
{{
  "scenarios": [
    {{
      "id": "S1",
      "name": "...",
      "description": "...",
      "likelihood": 0.7,
      "outcome": "...",
      "pros": ["..."],
      "cons": ["..."],
      "required_actions": ["..."]
    }}
  ],
  "recommended": "S1",
  "comparison_matrix": {{}}
}}"""
        return self._call_llm_json(prompt)
    
    def _brainstorm_enhanced(self, question, context, gathered_info, conclusions) -> Dict:
        """Ø¹ØµÙ Ø°Ù‡Ù†ÙŠ Ù…Ø­Ø³Ù‘Ù† Ù…Ø¹ ØªÙ‚ÙŠÙŠÙ…"""
        # Ø£ÙˆÙ„Ø§Ù‹: ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£ÙÙƒØ§Ø±
        prompt = f"""Ø¹ØµÙ Ø°Ù‡Ù†ÙŠ Ù„Ù„Ø³Ø¤Ø§Ù„ (Ø¨Ø¯ÙˆÙ† ØªÙ‚ÙŠÙŠÙ…):

Ø§Ù„Ø³Ø¤Ø§Ù„: {question}
Ø§Ù„Ø³ÙŠØ§Ù‚: {context if context else "Ù„Ø§ ÙŠÙˆØ¬Ø¯"}

ÙˆÙ„Ù‘Ø¯ Ø£ÙƒØ¨Ø± Ø¹Ø¯Ø¯ Ù…Ù† Ø§Ù„Ø£ÙÙƒØ§Ø± Ø§Ù„Ù…ØªÙ†ÙˆØ¹Ø©.

Ø£Ø¬Ø¨ Ø¨Ù€ JSON:
{{
  "ideas": [
    {{"text": "...", "category": "Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©/Ø¥Ø¬Ø±Ø§Ø¦ÙŠØ©/Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ©/ØºÙŠØ± ØªÙ‚Ù„ÙŠØ¯ÙŠØ©"}}
  ],
  "wild_ideas": ["..."],
  "combinations": ["..."]
}}"""
        
        raw_result = self._call_llm_json(prompt)
        
        # Ø«Ø§Ù†ÙŠØ§Ù‹: ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£ÙÙƒØ§Ø±
        evaluated_ideas = []
        for idea_data in raw_result.get("ideas", []):
            idea = self.idea_evaluator.evaluate(idea_data.get("text", ""), context)
            evaluated_ideas.append({
                "text": idea.content,
                "category": idea.category.value,
                "potential": idea.potential,
                "feasibility": idea.feasibility,
                "risk": idea.risk,
                "score": idea.score
            })
            self.current_session.ideas.append(idea)
        
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø·
        evaluated_ideas.sort(key=lambda x: x["score"], reverse=True)
        
        return {
            "ideas": evaluated_ideas,
            "top_ideas": evaluated_ideas[:5],
            "wild_ideas": raw_result.get("wild_ideas", []),
            "combinations": raw_result.get("combinations", []),
            "total_ideas": len(evaluated_ideas)
        }
    
    def _find_contradictions_enhanced(self, question, context, gathered_info, conclusions) -> Dict:
        """ÙƒØ´Ù Ø§Ù„ØªÙ†Ø§Ù‚Ø¶Ø§Øª Ø§Ù„Ù…Ø­Ø³Ù‘Ù†"""
        # ÙƒØ´Ù Ù…Ù†Ø·Ù‚ÙŠ Ø£ÙˆÙ„Ø§Ù‹
        logical_contradictions = self.contradiction_detector.detect(gathered_info)
        
        # ÙƒØ´Ù Ø¨Ù€ LLM
        info_text = "\n".join([
            f"- {item.get('content', str(item))[:200]}"
            for item in gathered_info[:10]
        ])
        
        prompt = f"""Ø§Ø¨Ø­Ø« Ø¹Ù† ØªÙ†Ø§Ù‚Ø¶Ø§Øª ÙÙŠ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª:

Ø§Ù„Ø³Ø¤Ø§Ù„: {question}
Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª:
{info_text if info_text else "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"}

Ø£Ø¬Ø¨ Ø¨Ù€ JSON:
{{
  "contradictions": [
    {{
      "item1": "...",
      "item2": "...",
      "type": "Ù…Ø¨Ø§Ø´Ø±/Ø¶Ù…Ù†ÙŠ/Ø¸Ø§Ù‡Ø±ÙŠ/Ø²Ù…Ù†ÙŠ",
      "explanation": "...",
      "severity": 0.7,
      "resolution": "..."
    }}
  ],
  "consistent_facts": ["..."],
  "needs_verification": ["..."]
}}"""
        
        llm_result = self._call_llm_json(prompt)
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        all_contradictions = []
        
        # Ù…Ù† Ø§Ù„ÙƒØ§Ø´Ù Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ
        for c in logical_contradictions:
            all_contradictions.append(c.to_dict())
            self.current_session.contradictions.append(c)
        
        # Ù…Ù† LLM
        for c in llm_result.get("contradictions", []):
            all_contradictions.append(c)
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
        unique = []
        seen = set()
        for c in all_contradictions:
            key = f"{c.get('item1', '')}|{c.get('item2', '')}"
            if key not in seen:
                seen.add(key)
                unique.append(c)
        
        return {
            "contradictions_found": len(unique) > 0,
            "contradictions": unique,
            "logical_detections": len(logical_contradictions),
            "llm_detections": len(llm_result.get("contradictions", [])),
            "consistent_facts": llm_result.get("consistent_facts", []),
            "needs_verification": llm_result.get("needs_verification", [])
        }
    
    def _multi_perspective(self, question, context, gathered_info, conclusions) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø²ÙˆØ§ÙŠØ§"""
        prompt = f"""Ø­Ù„Ù„ Ù…Ù† ÙˆØ¬Ù‡Ø§Øª Ù†Ø¸Ø± Ù…Ø®ØªÙ„ÙØ©:

Ø§Ù„Ù‚Ø¶ÙŠØ©: {question}
Ø§Ù„Ø³ÙŠØ§Ù‚: {context if context else "Ù„Ø§ ÙŠÙˆØ¬Ø¯"}

Ù‚Ø¯Ù… 4 ÙˆØ¬Ù‡Ø§Øª Ù†Ø¸Ø±: Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©ØŒ Ø¹Ù…Ù„ÙŠØ©ØŒ Ø£Ø®Ù„Ø§Ù‚ÙŠØ©ØŒ ÙˆØ§Ù‚ØªØµØ§Ø¯ÙŠØ©.

Ø£Ø¬Ø¨ Ø¨Ù€ JSON:
{{
  "perspectives": [
    {{
      "viewpoint": "...",
      "position": "...",
      "arguments": ["..."],
      "weaknesses": ["..."],
      "confidence": 0.7,
      "key_sources": ["..."]
    }}
  ],
  "points_of_agreement": ["..."],
  "points_of_conflict": ["..."],
  "synthesis": "...",
  "recommended_position": "..."
}}"""
        
        result = self._call_llm_json(prompt)
        
        # ØªØ³Ø¬ÙŠÙ„ ÙˆØ¬Ù‡Ø§Øª Ø§Ù„Ù†Ø¸Ø±
        for p in result.get("perspectives", []):
            viewpoint = Viewpoint(
                perspective=p.get("viewpoint", ""),
                position=p.get("position", ""),
                arguments=p.get("arguments", []),
                weaknesses=p.get("weaknesses", []),
                confidence=p.get("confidence", 0.7),
                sources=p.get("key_sources", [])
            )
            self.current_session.viewpoints.append(viewpoint)
        
        return result
    
    def _challenge_assumptions(self, question, context, gathered_info, conclusions) -> Dict:
        """ØªØ­Ø¯ÙŠ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶Ø§Øª"""
        conclusions_text = "\n".join([f"- {c}" for c in conclusions[:5]])
        
        prompt = f"""ÙƒÙ† Ù…Ø­Ø§Ù…ÙŠ Ø§Ù„Ø´ÙŠØ·Ø§Ù† ÙˆØªØ­Ø¯ÙÙ‘ Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª:

Ø§Ù„Ø³Ø¤Ø§Ù„: {question}
Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª:
{conclusions_text if conclusions_text else "Ù„Ø§ ØªÙˆØ¬Ø¯"}

Ø£Ø¬Ø¨ Ø¨Ù€ JSON:
{{
  "challenges": [
    {{
      "conclusion": "...",
      "challenge": "...",
      "potential_flaw": "...",
      "counter_argument": "...",
      "severity": 0.7
    }}
  ],
  "hidden_assumptions": ["..."],
  "overlooked_factors": ["..."],
  "stress_test": "...",
  "revised_confidence": 0.6
}}"""
        return self._call_llm_json(prompt)
    
    def _analogical_reasoning(self, question, context, gathered_info, conclusions) -> Dict:
        """Ø§Ù„ØªÙÙƒÙŠØ± Ø¨Ø§Ù„Ù‚ÙŠØ§Ø³ - Ø¬Ø¯ÙŠØ¯"""
        prompt = f"""Ù‚Ø³ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø§Øª Ù…Ø´Ø§Ø¨Ù‡Ø©:

Ø§Ù„Ù‚Ø¶ÙŠØ©: {question}
Ø§Ù„Ø³ÙŠØ§Ù‚: {context if context else "Ù„Ø§ ÙŠÙˆØ¬Ø¯"}

Ø§Ø¨Ø­Ø« Ø¹Ù† Ø³ÙˆØ§Ø¨Ù‚ Ø£Ùˆ Ø­Ø§Ù„Ø§Øª Ù…Ø´Ø§Ø¨Ù‡Ø© ÙˆÙ‚Ø³ Ø¹Ù„ÙŠÙ‡Ø§.

Ø£Ø¬Ø¨ Ø¨Ù€ JSON:
{{
  "similar_cases": [
    {{
      "case": "...",
      "similarity": 0.8,
      "outcome": "...",
      "applicable_rules": ["..."]
    }}
  ],
  "analogy_basis": "ÙˆØ¬Ù‡ Ø§Ù„Ø´Ø¨Ù‡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ",
  "differences": ["..."],
  "predicted_outcome": "...",
  "confidence": 0.7
}}"""
        return self._call_llm_json(prompt)
    
    def _causal_analysis(self, question, context, gathered_info, conclusions) -> Dict:
        """Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¨Ø¨ÙŠ - Ø¬Ø¯ÙŠØ¯"""
        prompt = f"""Ø­Ù„Ù„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ø³Ø¨Ø¨ÙŠØ©:

Ø§Ù„Ù‚Ø¶ÙŠØ©: {question}
Ø§Ù„Ø³ÙŠØ§Ù‚: {context if context else "Ù„Ø§ ÙŠÙˆØ¬Ø¯"}

Ø­Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬.

Ø£Ø¬Ø¨ Ø¨Ù€ JSON:
{{
  "causal_chain": [
    {{
      "cause": "...",
      "effect": "...",
      "strength": 0.8,
      "evidence": "..."
    }}
  ],
  "root_cause": "...",
  "contributing_factors": ["..."],
  "but_for_test": "Ù„Ùˆ Ù„Ù… ÙŠØ­Ø¯Ø« X Ù„Ù…Ø§ Ø­Ø¯Ø« Y",
  "counterfactual": "..."
}}"""
        return self._call_llm_json(prompt)
    
    def _temporal_analysis(self, question, context, gathered_info, conclusions) -> Dict:
        """Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ - Ø¬Ø¯ÙŠØ¯"""
        prompt = f"""Ø­Ù„Ù„ Ø§Ù„Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ø²Ù…Ù†ÙŠØ©:

Ø§Ù„Ù‚Ø¶ÙŠØ©: {question}
Ø§Ù„Ø³ÙŠØ§Ù‚: {context if context else "Ù„Ø§ ÙŠÙˆØ¬Ø¯"}

Ø­Ø¯Ø¯ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® ÙˆØ§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ù…Ù‡Ù…Ø©.

Ø£Ø¬Ø¨ Ø¨Ù€ JSON:
{{
  "timeline": [
    {{"event": "...", "date": "...", "significance": "..."}}
  ],
  "deadlines": [
    {{"deadline": "...", "for": "...", "days_remaining": 30, "legal_basis": "..."}}
  ],
  "prescription_issues": ["..."],
  "time_sensitive_actions": ["..."]
}}"""
        return self._call_llm_json(prompt)
    
    def _full_analysis_enhanced(self, question, context, gathered_info, conclusions) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù…Ø­Ø³Ù‘Ù†"""
        results = {}
        
        # 1. ØªÙÙƒÙŠÙƒ
        results["decomposition"] = self._decompose(question, context, gathered_info, conclusions)
        
        # 2. ÙØ±Ø¶ÙŠØ§Øª
        results["hypotheses"] = self._hypothesize(question, context, gathered_info, conclusions)
        
        # 3. ÙˆØ¬Ù‡Ø§Øª Ù†Ø¸Ø±
        results["perspectives"] = self._multi_perspective(question, context, gathered_info, conclusions)
        
        # 4. ØªÙ†Ø§Ù‚Ø¶Ø§Øª
        if gathered_info:
            results["contradictions"] = self._find_contradictions_enhanced(
                question, context, gathered_info, conclusions
            )
        
        # 5. ØªØ­Ø¯ÙŠØ§Øª
        if conclusions:
            results["challenges"] = self._challenge_assumptions(
                question, context, gathered_info, conclusions
            )
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
        confidence_scores = [
            results.get("hypotheses", {}).get("most_likely_probability", 0.5),
            results.get("perspectives", {}).get("synthesis_confidence", 0.5)
        ]
        
        overall_confidence = np.mean([c for c in confidence_scores if c > 0])
        
        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø±Ø¤Ù‰
        key_insights = []
        for r in results.values():
            if isinstance(r, dict):
                insights = r.get("key_insights", []) or r.get("insights", [])
                key_insights.extend(insights[:2])
        
        self.current_session.final_insights = key_insights
        self.current_session.confidence = overall_confidence
        
        return {
            "summary": f"ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ø³Ø¤Ø§Ù„: {question[:50]}...",
            "results": results,
            "key_insights": key_insights[:10],
            "confidence": overall_confidence,
            "complexity_score": results.get("decomposition", {}).get("complexity_score", 5),
            "session_id": self.current_session.session_id
        }
    
    def _call_llm_json(self, prompt: str) -> Dict[str, Any]:
        """Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ LLM Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© JSON Ù…Ø­Ø³Ù‘Ù†Ø©"""
        if not self.llm_client:
            return {"error": "No LLM client configured"}
        
        messages = [
            {"role": "system", "content": "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø®Ø¨ÙŠØ±. Ø£Ø¬Ø¨ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø¨Ù€ JSON ØµØ§Ù„Ø­ ÙÙ‚Ø·."},
            {"role": "user", "content": prompt}
        ]
        
        response = self.llm_client.chat_completion(
            messages=messages,
            temperature=0.5,
            max_tokens=2000
        )
        
        return self._parse_json_response(response)
    
    def _parse_json_response(self, response: str) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© JSON Ù…Ø­Ø³Ù‘Ù†Ø©"""
        try:
            # Ù…Ø­Ø§ÙˆÙ„Ø© 1: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† code block
            if "```json" in response:
                json_str = response.split("```json")[1].split("```")[0].strip()
                return json.loads(json_str)
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© 2: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† code block Ø¹Ø§Ù…
            if "```" in response:
                json_str = response.split("```")[1].split("```")[0].strip()
                return json.loads(json_str)
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© 3: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {}
            if "{" in response:
                start = response.find("{")
                end = response.rfind("}") + 1
                json_str = response[start:end]
                return json.loads(json_str)
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© 4: Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© ÙƒØ§Ù…Ù„Ø©
            return json.loads(response.strip())
            
        except json.JSONDecodeError as e:
            logger.warning(f"JSON parse failed: {e}")
            return {
                "raw_response": response,
                "parse_error": str(e),
                "partial_extraction": self._extract_partial_json(response)
            }
    
    def _extract_partial_json(self, text: str) -> Dict:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ø²Ø¦ÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        result = {}
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù…
        import re
        list_pattern = r'"(\w+)":\s*\[(.*?)\]'
        for match in re.finditer(list_pattern, text, re.DOTALL):
            key, value = match.groups()
            items = re.findall(r'"([^"]+)"', value)
            result[key] = items
        
        return result
    
    def can_handle(self, query: str) -> float:
        """ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù‚Ø¯Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"""
        score = 0.3
        
        # Ø·ÙˆÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„
        if len(query.split()) > 20:
            score += 0.2
        
        # ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
        complex_keywords = ["Ø¥Ø°Ø§", "Ù…Ø§ Ø§Ù„ÙØ±Ù‚", "Ù‚Ø§Ø±Ù†", "Ù„ÙƒÙ†", "Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ©"]
        if any(kw in query for kw in complex_keywords):
            score += 0.2
        
        # Ø£Ø³Ø¦Ù„Ø©
        if "?" in query or "ØŸ" in query:
            score += 0.1
        
        return min(1.0, score)


# ============================================================
# BACKWARD COMPATIBILITY
# ============================================================

# Alias Ù„Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù‚Ø¯ÙŠÙ…
DeepThinkingTool = EnhancedDeepThinkingTool


# ============================================================
# EXPORTS
# ============================================================

__all__ = [
    "EnhancedDeepThinkingTool",
    "DeepThinkingTool",  # Alias
    "ThinkingMode",
    "Viewpoint",
    "Contradiction",
    "Idea",
    "ThinkingSession"
]
