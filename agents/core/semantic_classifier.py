"""
ðŸŽ¯ Semantic Complexity Classifier

Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ keywords Ø¬Ø§Ù…Ø¯Ø©ØŒ Ù†Ø³ØªØ®Ø¯Ù… LLM Ù„Ù„ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ÙŠ.
"""

import asyncio
import json
import re
import logging
from typing import Dict, Any
from langchain_core.messages import SystemMessage

logger = logging.getLogger(__name__)

# ==================== SEMANTIC ANALYSIS PROMPT ====================

COMPLEXITY_ANALYSIS_PROMPT = """
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØµÙ†ÙŠÙ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯.

## Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±:
{query}

## Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³Ø§Ø¨Ù‚ (Ø¥Ù† ÙˆÙØ¬Ø¯):
{context}

---

## Ø§Ù„Ù…Ù‡Ù…Ø©:

ØµÙ†Ù‘Ù Ù‡Ø°Ø§ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø± Ø­Ø³Ø¨ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯:

### 1ï¸âƒ£ Ø¨Ø³ÙŠØ· (simple):
**Ø§Ù„Ø®ØµØ§Ø¦Øµ:**
- Ø³Ø¤Ø§Ù„ Ù…Ø¨Ø§Ø´Ø± Ø¹Ù† Ù…Ø§Ø¯Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…Ø­Ø¯Ø¯Ø©
- Ø·Ù„Ø¨ ØªØ¹Ø±ÙŠÙ Ø£Ùˆ Ù…Ø¹Ù„ÙˆÙ…Ø© ÙˆØ§Ø¶Ø­Ø©
- Ø³Ø¤Ø§Ù„ Ø¥Ø¬Ø±Ø§Ø¦ÙŠ Ø¨Ø³ÙŠØ· (ÙƒÙŠÙ Ø£Ø«Ø¨ØªØŸ Ù…Ø§ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§ØªØŸ)
- Ø§Ø³ØªÙØ³Ø§Ø± Ø¹Ù† Ù…ÙÙ‡ÙˆÙ… Ù‚Ø§Ù†ÙˆÙ†ÙŠ ÙˆØ§Ø­Ø¯

**Ø£Ù…Ø«Ù„Ø©:**
- "Ù…Ø§ Ù‡ÙŠ Ø´Ø±ÙˆØ· Ø§Ù„Ù‡Ø¨Ø©ØŸ"
- "ÙƒÙŠÙ ÙŠØªÙ… Ø¥Ø«Ø¨Ø§Øª Ø§Ù„Ù‡Ø¨Ø©ØŸ"
- "Ù…Ø§ ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø¹Ù‚Ø¯ØŸ"
- "Ø§Ù„Ù…Ø§Ø¯Ø© 375 Ø¹Ù† Ø¥ÙŠÙ‡ØŸ"

---

### 2ï¸âƒ£ Ù…ØªÙˆØ³Ø· (medium):
**Ø§Ù„Ø®ØµØ§Ø¦Øµ:**
- ÙŠØ­ØªØ§Ø¬ ØªØ­Ù„ÙŠÙ„ Ø¹Ø¯Ø© Ù…ÙˆØ§Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
- Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø£Ø­ÙƒØ§Ù… Ù…Ø®ØªÙ„ÙØ©
- Ø³Ø¤Ø§Ù„ Ø¹Ù† ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù…Ù„ÙŠ Ù„Ù‚Ø§Ø¹Ø¯Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
- Ø§Ø³ØªÙØ³Ø§Ø± Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø¬ÙˆØ§Ù†Ø¨

**Ø£Ù…Ø«Ù„Ø©:**
- "Ù…Ø§ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ù‡Ø¨Ø© ÙˆØ§Ù„ÙˆØµÙŠØ©ØŸ"
- "ÙƒÙŠÙ Ø£Ø·Ø¨Ù‚ Ø§Ù„Ù…Ø§Ø¯Ø© 375 ÙÙŠ Ø­Ø§Ù„ØªÙŠØŸ"
- "Ù…Ø§ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø±Ø¬ÙˆØ¹ ÙÙŠ Ø§Ù„Ù‡Ø¨Ø© Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠØ©ØŸ"

---

### 3ï¸âƒ£ Ù…Ø¹Ù‚Ø¯ (complex):
**Ø§Ù„Ø®ØµØ§Ø¦Øµ:**
- ÙŠØ­ØªØ§Ø¬ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ÙƒØ§Ù…Ù„Ø©
- ØªØ­Ù„ÙŠÙ„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ (Ù‚Ø§Ù†ÙˆÙ†ÙŠ + Ø¹Ù…Ù„ÙŠ + Ø²Ù…Ù†ÙŠ)
- Ø§Ø³ØªØ´Ø§Ø±Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù‚Ø¶ÙŠØ© Ø£Ùˆ Ù…ÙˆÙ‚Ù
- ÙŠØªØ·Ù„Ø¨ ØªØ®Ø·ÙŠØ· ÙˆÙˆØ«Ø§Ø¦Ù‚

**Ø£Ù…Ø«Ù„Ø©:**
- "Ø£Ø­ØªØ§Ø¬ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù‚Ø¶ÙŠØ©..."
- "ÙƒÙŠÙ Ø£Ø­Ù…ÙŠ Ù†ÙØ³ÙŠ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ§Ù‹ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆÙ‚Ù..."
- "Ø³Ø§Ø¹Ø¯Ù†ÙŠ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø®Ø·Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©..."

---

## Ø§Ù„ØµÙŠØºØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (JSON):

**CRITICAL: Return ONLY valid JSON - no markdown, no explanations.**

```json
{{
  "complexity": "simple",
  "confidence": 0.95,
  "reasoning": "Ø³Ø¤Ø§Ù„ Ù…Ø¨Ø§Ø´Ø± Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…Ø­Ø¯Ø¯Ø©",
  "estimated_time": "15s"
}}
```

**complexity values:** "simple" | "medium" | "complex"  
**confidence:** 0.0 - 1.0 (Ø«Ù‚ØªÙƒ ÙÙŠ Ø§Ù„ØªØµÙ†ÙŠÙ)  
**estimated_time:** ØªÙ‚Ø¯ÙŠØ± Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨

---

Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø¢Ù†:
"""


# ==================== HELPER FUNCTIONS ====================

def _is_obviously_simple(query: str) -> bool:
    """
    Fast heuristics Ù„Ù„Ù€ obviously simple queries
    
    Returns True Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø³ÙŠØ· Ø¨ÙˆØ¶ÙˆØ­ (Ø¨Ø¯ÙˆÙ† Ø­Ø§Ø¬Ø© Ù„Ù€ LLM)
    """
    query_lower = query.lower().strip()
    words = query.split()
    
    # 1. Very short queries (â‰¤ 8 words) often simple
    if len(words) <= 8:
        # Direct question patterns
        simple_starts = [
            "Ù…Ø§ Ù‡Ùˆ", "Ù…Ø§ Ù‡ÙŠ", "Ù…Ù† Ù‡Ùˆ", "Ù…Ù† Ù‡ÙŠ",
            "ÙƒÙŠÙ ÙŠØªÙ…", "Ù…ØªÙ‰ ÙŠØªÙ…", "Ø£ÙŠÙ†",
            "Ù…Ø§Ø°Ø§", "Ù‡Ù„ ÙŠØ¬ÙˆØ²", "Ù‡Ù„ ÙŠÙ…ÙƒÙ†"
        ]
        
        if any(query_lower.startswith(start) for start in simple_starts):
            return True
    
    # 2. Direct article reference (e.g., "Ø§Ù„Ù…Ø§Ø¯Ø© 375")
    if re.search(r"Ø§Ù„Ù…Ø§Ø¯Ø©\s+\d+", query_lower):
        # If query is JUST asking about the article
        if len(words) <= 10:
            return True
    
    # 3. Definition requests
    definition_patterns = [
        r"Ù…Ø§\s+(Ù‡Ùˆ|Ù‡ÙŠ)\s+ØªØ¹Ø±ÙŠÙ",
        r"ØªØ¹Ø±ÙŠÙ\s+\w+",
        r"Ù…Ø¹Ù†Ù‰\s+\w+"
    ]
    
    if any(re.search(p, query_lower) for p in definition_patterns):
        return True
    
    return False


def _is_obviously_complex(query: str) -> bool:
    """
    Fast heuristics Ù„Ù„Ù€ obviously complex queries
    
    Returns True Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø¹Ù‚Ø¯ Ø¨ÙˆØ¶ÙˆØ­
    """
    query_lower = query.lower()
    
    # 1. Strategy/planning keywords
    complex_keywords = [
        "Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©", "Ø®Ø·Ø©", "ÙƒÙŠÙ Ø£ØªØ¹Ø§Ù…Ù„", "Ù…Ø§Ø°Ø§ Ø£ÙØ¹Ù„",
        "Ø³Ø§Ø¹Ø¯Ù†ÙŠ ÙÙŠ", "Ù…Ø­ØªØ§Ø¬ Ù…Ø´ÙˆØ±Ø©", "Ù‚Ø¶ÙŠØ©", "Ù…ÙˆÙ‚Ù Ù‚Ø§Ù†ÙˆÙ†ÙŠ",
        "Ø­Ù…Ø§ÙŠØ© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©", "Ø¯ÙØ§Ø¹", "Ø§ØªØ®Ø§Ø° Ø¥Ø¬Ø±Ø§Ø¡"
    ]
    
    if any(kw in query_lower for kw in complex_keywords):
        return True
    
    # 2. Very long queries (> 40 words) often complex
    if len(query.split()) > 40:
        return True
    
    # 3. Multiple questions (contains "Ùˆ" + question words multiple times)
    question_words = ["ÙƒÙŠÙ", "Ù…Ø§Ø°Ø§", "Ù…Ø§", "Ù‡Ù„", "Ù…ØªÙ‰", "Ø£ÙŠÙ†"]
    question_count = sum(1 for qw in question_words if qw in query_lower)
    
    if question_count >= 3:  # 3+ questions in one â†’ complex
        return True
    
    return False


async def _classify_complexity_semantic(
    query: str,
    context: Dict[str, Any],
    llm
) -> Dict[str, Any]:
    """
    Ø§Ø³ØªØ®Ø¯Ø§Ù… LLM Ù„Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø³ÙŠØ§Ù‚ÙŠ
    
    Returns:
        {
            "complexity": "simple|medium|complex",
            "confidence": 0.0-1.0,
            "reasoning": "...",
            "estimated_time": "..."
        }
    """
    
    # Format context
    context_str = "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø³ÙŠØ§Ù‚ Ø³Ø§Ø¨Ù‚"
    if context and context.get("facts_snapshot"):
        facts = context.get("facts_snapshot", {})
        context_str = json.dumps(facts, ensure_ascii=False, indent=2)[:300]
    
    prompt = COMPLEXITY_ANALYSIS_PROMPT.format(
        query=query,
        context=context_str
    )
    
    try:
        response = await asyncio.wait_for(
            llm.ainvoke([SystemMessage(content=prompt)]),
            timeout=5  # Fast classification (5s max)
        )
        
        # Parse JSON (handle markdown if present)
        content = response.content.strip()
        
        # Strip markdown if present
        if content.startswith("```json"):
            lines = content.split('\n')
            content = '\n'.join(lines[1:-1])
        elif content.startswith("```"):
            lines = content.split('\n')
            content = '\n'.join(lines[1:-1])
        
        result = json.loads(content)
        
        # Validate
        if "complexity" not in result:
            raise ValueError("Missing 'complexity' field")
        
        return result
        
    except asyncio.TimeoutError:
        logger.warning("â±ï¸ Semantic classification timeout - defaulting to medium")
        return {
            "complexity": "medium",
            "confidence": 0.5,
            "reasoning": "Timeout - defaulted to medium",
            "estimated_time": "30s"
        }
        
    except Exception as e:
        logger.error(f"âŒ Semantic classification failed: {e}")
        return {
            "complexity": "medium",
            "confidence": 0.5,
            "reasoning": f"Error: {str(e)} - defaulted to medium",
            "estimated_time": "30s"
        }


# ==================== MAIN FUNCTION ====================

async def determine_complexity_hybrid(
    query: str,
    context: Dict[str, Any],
    llm
) -> str:
    """
    ðŸŽ¯ Hybrid Approach: Fast heuristics + Semantic LLM
    
    Returns: "simple" | "medium" | "complex"
    """
    
    # ===== PHASE 1: Fast Heuristics (0.001s) =====
    
    # Check if obviously simple
    if _is_obviously_simple(query):
        logger.info(f"âš¡ Fast classification: SIMPLE (heuristic)")
        return "simple"
    
    # Check if obviously complex
    if _is_obviously_complex(query):
        logger.info(f"âš¡ Fast classification: COMPLEX (heuristic)")
        return "complex"
    
    # ===== PHASE 2: Semantic LLM (5s) =====
    
    logger.info(f"ðŸ§  Uncertain - using semantic classification...")
    
    result = await _classify_complexity_semantic(query, context, llm)
    
    complexity = result.get("complexity", "medium")
    confidence = result.get("confidence", 0.5)
    reasoning = result.get("reasoning", "No reasoning")
    
    logger.info(f"ðŸŽ¯ Semantic classification: {complexity.upper()} (confidence: {confidence:.2f})")
    logger.info(f"   Reasoning: {reasoning}")
    
    return complexity


# ==================== EXPORT ====================

__all__ = [
    "determine_complexity_hybrid",
    "COMPLEXITY_ANALYSIS_PROMPT"
]
