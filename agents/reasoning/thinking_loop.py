"""
Advanced Unified Thinking Loop v2.0
ุญููุฉ ุงูุชูููุฑ ุงูููุญุฏุฉ ุงููุชูุฏูุฉ

ุงูุชุญุณููุงุช:
1. ุฏูุฌ Neural-Symbolic Reasoning
2. Probabilistic Confidence Calculation
3. Caching & Memoization
4. Feedback Learning Loop
5. Advanced Error Recovery
6. Temporal & Deontic Logic Integration
7. Counterfactual Analysis
8. Multi-Agent Deliberation
"""

import logging
import time
import hashlib
import json
from typing import List, Dict, Any, Optional, Tuple, Callable
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime, timedelta
from abc import ABC, abstractmethod
from collections import defaultdict
import numpy as np
from functools import lru_cache

logger = logging.getLogger(__name__)


# ============================================================
# ENUMS & CONSTANTS
# ============================================================

class ThinkingStrategy(Enum):
    """ุงุณุชุฑุงุชูุฌูุงุช ุงูุชูููุฑ ุงููุชูุฏูุฉ"""
    DIRECT = "direct"                    # ุจุณูุท: ุจุญุซ + ุฅุฌุงุจุฉ
    CHAIN_OF_THOUGHT = "cot"            # ูุชูุณุท: ุฎุทูุฉ ุจุฎุทูุฉ
    MULTI_PATH = "multi_path"           # ูุนูุฏ: ูุณุงุฑุงุช ูุชุนุฏุฏุฉ
    TREE_OF_THOUGHT = "tot"             # ูุนูุฏ ุฌุฏุงู: ุดุฌุฑุฉ ุชูููุฑ
    DEBATE = "debate"                   # ูุซูุฑ ููุฌุฏู: ููุงุธุฑุฉ
    DECOMPOSE = "decompose"             # ูุฑูุจ: ุชูููู ูุชุฌููุน
    ANALOGICAL = "analogical"           # ุฌุฏูุฏ: ููุงุณ ุนูู ุณูุงุจู


class ConfidenceLevel(Enum):
    """ูุณุชููุงุช ุงูุซูุฉ"""
    VERY_HIGH = (0.9, 1.0, "ุซูุฉ ุนุงููุฉ ุฌุฏุงู")
    HIGH = (0.75, 0.9, "ุซูุฉ ุนุงููุฉ")
    MODERATE = (0.5, 0.75, "ุซูุฉ ูุชูุณุทุฉ")
    LOW = (0.25, 0.5, "ุซูุฉ ููุฎูุถุฉ")
    VERY_LOW = (0.0, 0.25, "ุซูุฉ ููุฎูุถุฉ ุฌุฏุงู")
    
    @classmethod
    def from_score(cls, score: float) -> 'ConfidenceLevel':
        for level in cls:
            if level.value[0] <= score < level.value[1]:
                return level
        return cls.VERY_HIGH if score >= 1.0 else cls.VERY_LOW


class ReasoningMode(Enum):
    """ุฃููุงุท ุงูุชูููุฑ"""
    DEDUCTIVE = "deductive"      # ุงุณุชูุจุงุทู: ูู ุงูุนุงู ููุฎุงุต
    INDUCTIVE = "inductive"      # ุงุณุชูุฑุงุฆู: ูู ุงูุฎุงุต ููุนุงู
    ABDUCTIVE = "abductive"      # ุชูุณูุฑู: ุฃูุถู ุชูุณูุฑ
    ANALOGICAL = "analogical"    # ููุงุณู: ููุงุฑูุฉ ุจุญุงูุงุช ูุดุงุจูุฉ


# ============================================================
# DATA STRUCTURES
# ============================================================

@dataclass
class ThinkingInput:
    """ูุฏุฎูุงุช ุญููุฉ ุงูุชูููุฑ ุงููุชูุฏูุฉ"""
    question: str
    context: str = ""
    force_strategy: Optional[ThinkingStrategy] = None
    force_mode: Optional[ReasoningMode] = None
    require_citations: bool = True
    max_thinking_time: float = 30.0  # ุซุงููุฉ
    min_confidence: float = 0.5
    include_counterfactuals: bool = False
    check_deadlines: bool = True
    user_id: Optional[str] = None  # ููุชุฎุตูุต


@dataclass
class ConfidenceBreakdown:
    """ุชูุตูู ุฏุฑุฌุฉ ุงูุซูุฉ"""
    source_quality: float      # ุฌูุฏุฉ ุงููุตุงุฏุฑ
    source_agreement: float    # ุงุชูุงู ุงููุตุงุฏุฑ
    reasoning_validity: float  # ุตุญุฉ ุงูุงุณุชุฏูุงู
    coverage: float           # ุชุบุทูุฉ ุงูุณุคุงู
    recency: float           # ุญุฏุงุซุฉ ุงููุนูููุงุช
    
    @property
    def overall(self) -> float:
        weights = [0.25, 0.25, 0.2, 0.15, 0.15]
        values = [
            self.source_quality,
            self.source_agreement,
            self.reasoning_validity,
            self.coverage,
            self.recency
        ]
        return sum(w * v for w, v in zip(weights, values))
    
    def to_dict(self) -> Dict[str, float]:
        return {
            "source_quality": round(self.source_quality, 3),
            "source_agreement": round(self.source_agreement, 3),
            "reasoning_validity": round(self.reasoning_validity, 3),
            "coverage": round(self.coverage, 3),
            "recency": round(self.recency, 3),
            "overall": round(self.overall, 3)
        }


@dataclass
class Citation:
    """ุงุณุชุดูุงุฏ ููุซู"""
    source_id: str
    source_type: str  # article, ruling, principle
    text: str
    relevance_score: float
    page_or_section: Optional[str] = None


@dataclass
class ReasoningStep:
    """ุฎุทูุฉ ูู ุณูุณูุฉ ุงูุชูููุฑ"""
    step_id: int
    description: str
    reasoning_type: ReasoningMode
    inputs: List[str]
    output: str
    confidence: float
    citations: List[Citation] = field(default_factory=list)
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class CounterfactualAnalysis:
    """ุชุญููู ุงูุจุฏูู ุงููุถุงุฏ"""
    original_conclusion: str
    changed_fact: str
    new_conclusion: str
    impact_level: str  # high, medium, low
    explanation: str


@dataclass
class DeadlineAlert:
    """ุชูุจูู ุจููุนุฏ ูุงูููู"""
    deadline_type: str
    deadline_date: datetime
    days_remaining: int
    action_required: str
    legal_basis: str


@dataclass
class ThinkingOutput:
    """ูุฎุฑุฌุงุช ุญููุฉ ุงูุชูููุฑ ุงููุชูุฏูุฉ"""
    # ุงูุฅุฌุงุจุฉ ุงูุฑุฆูุณูุฉ
    answer: str
    summary: str  # ููุฎุต ูุตูุฑ
    
    # ุงูุซูุฉ
    confidence: float
    confidence_breakdown: ConfidenceBreakdown
    confidence_level: ConfidenceLevel
    
    # ุงูุงุณุชุฑุงุชูุฌูุฉ
    strategy_used: ThinkingStrategy
    reasoning_mode: ReasoningMode
    
    # ุงูุชุตููู
    domain: str
    complexity: str
    
    # ุงููุตุงุฏุฑ
    sources_retrieved: int
    sources_used: int
    sources_filtered: int
    citations: List[Citation]
    
    # ุณูุณูุฉ ุงูุชูููุฑ
    reasoning_steps: List[ReasoningStep]
    reasoning_trace: List[str]
    
    # ุชุญูููุงุช ุฅุถุงููุฉ
    counterfactuals: List[CounterfactualAnalysis] = field(default_factory=list)
    deadline_alerts: List[DeadlineAlert] = field(default_factory=list)
    related_questions: List[str] = field(default_factory=list)
    
    # ุชุญุฐูุฑุงุช
    warnings: List[str] = field(default_factory=list)
    uncited_claims: List[str] = field(default_factory=list)
    
    # ุฃุฏุงุก
    execution_time_ms: float = 0.0
    cache_hit: bool = False
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "answer": self.answer,
            "summary": self.summary,
            "confidence": self.confidence,
            "confidence_breakdown": self.confidence_breakdown.to_dict(),
            "confidence_level": self.confidence_level.value[2],
            "strategy": self.strategy_used.value,
            "domain": self.domain,
            "sources_used": self.sources_used,
            "citations_count": len(self.citations),
            "reasoning_steps": len(self.reasoning_steps),
            "warnings": self.warnings,
            "execution_time_ms": self.execution_time_ms
        }


# ============================================================
# CACHING SYSTEM
# ============================================================

class ThinkingCache:
    """ูุธุงู ุงูุชุฎุฒูู ุงููุคูุช ููุชูููุฑ"""
    
    def __init__(self, max_size: int = 1000, ttl_hours: int = 24):
        self.cache: Dict[str, Tuple[ThinkingOutput, datetime]] = {}
        self.max_size = max_size
        self.ttl = timedelta(hours=ttl_hours)
        self.hits = 0
        self.misses = 0
    
    def _hash_input(self, input: ThinkingInput) -> str:
        """ุชูููุฏ hash ูููุฏุฎูุงุช"""
        key_data = f"{input.question}|{input.context[:100]}|{input.force_strategy}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def get(self, input: ThinkingInput) -> Optional[ThinkingOutput]:
        """ุงุณุชุฑุฌุงุน ูู ุงููุงุด"""
        key = self._hash_input(input)
        
        if key in self.cache:
            output, timestamp = self.cache[key]
            if datetime.now() - timestamp < self.ttl:
                self.hits += 1
                output.cache_hit = True
                return output
            else:
                # ููุชูู ุงูุตูุงุญูุฉ
                del self.cache[key]
        
        self.misses += 1
        return None
    
    def set(self, input: ThinkingInput, output: ThinkingOutput):
        """ุญูุธ ูู ุงููุงุด"""
        if len(self.cache) >= self.max_size:
            # ุญุฐู ุงูุฃูุฏู
            oldest_key = min(self.cache, key=lambda k: self.cache[k][1])
            del self.cache[oldest_key]
        
        key = self._hash_input(input)
        self.cache[key] = (output, datetime.now())
    
    @property
    def hit_rate(self) -> float:
        total = self.hits + self.misses
        return self.hits / total if total > 0 else 0.0


# ============================================================
# CONFIDENCE CALCULATOR
# ============================================================

class AdvancedConfidenceCalculator:
    """ุญุงุณุจ ุงูุซูุฉ ุงููุชูุฏู"""
    
    def __init__(self):
        self.source_type_weights = {
            "law": 1.0,
            "regulation": 0.95,
            "ruling": 0.9,
            "principle": 0.85,
            "article": 0.8,
            "opinion": 0.6
        }
    
    def calculate(
        self,
        sources: List[Dict[str, Any]],
        reasoning_steps: List[ReasoningStep],
        question_coverage: float,
        source_dates: List[datetime] = None
    ) -> ConfidenceBreakdown:
        """ุญุณุงุจ ุงูุซูุฉ ุงูุชูุตููู"""
        
        # 1. ุฌูุฏุฉ ุงููุตุงุฏุฑ
        source_quality = self._calculate_source_quality(sources)
        
        # 2. ุงุชูุงู ุงููุตุงุฏุฑ
        source_agreement = self._calculate_agreement(sources)
        
        # 3. ุตุญุฉ ุงูุงุณุชุฏูุงู
        reasoning_validity = self._calculate_reasoning_validity(reasoning_steps)
        
        # 4. ุชุบุทูุฉ ุงูุณุคุงู
        coverage = question_coverage
        
        # 5. ุญุฏุงุซุฉ ุงููุนูููุงุช
        recency = self._calculate_recency(source_dates)
        
        return ConfidenceBreakdown(
            source_quality=source_quality,
            source_agreement=source_agreement,
            reasoning_validity=reasoning_validity,
            coverage=coverage,
            recency=recency
        )
    
    def _calculate_source_quality(self, sources: List[Dict]) -> float:
        """ุญุณุงุจ ุฌูุฏุฉ ุงููุตุงุฏุฑ"""
        if not sources:
            return 0.0
        
        scores = []
        for s in sources:
            source_type = s.get("type", "article")
            weight = self.source_type_weights.get(source_type, 0.5)
            relevance = s.get("relevance_score", 0.5)
            scores.append(weight * relevance)
        
        return np.mean(scores) if scores else 0.0
    
    def _calculate_agreement(self, sources: List[Dict]) -> float:
        """ุญุณุงุจ ุงุชูุงู ุงููุตุงุฏุฑ"""
        if len(sources) < 2:
            return 0.7  # ุงูุชุฑุงุถู ูููุตุฏุฑ ุงููุงุญุฏ
        
        # ุชุญููู ุจุณูุท ููุงุชูุงู (ูู ุงููุงูุน ุณูุณุชุฎุฏู NLP)
        # ููุชุฑุถ ุงุชูุงู ุฅุฐุง ูุงูุช ุงููุตุงุฏุฑ ูู ููุณ ุงููุฌุงู
        domains = [s.get("domain", "general") for s in sources]
        unique_domains = len(set(domains))
        
        if unique_domains == 1:
            return 0.9  # ูู ุงููุตุงุฏุฑ ูู ููุณ ุงููุฌุงู
        else:
            return max(0.5, 1.0 - (unique_domains - 1) * 0.1)
    
    def _calculate_reasoning_validity(self, steps: List[ReasoningStep]) -> float:
        """ุญุณุงุจ ุตุญุฉ ุงูุงุณุชุฏูุงู"""
        if not steps:
            return 0.5
        
        # ูุชูุณุท ุซูุฉ ุงูุฎุทูุงุช
        avg_confidence = np.mean([s.confidence for s in steps])
        
        # ููุงูุฃุฉ ููุฎุทูุงุช ุงููุฏุนููุฉ ุจุงุณุชุดูุงุฏุงุช
        cited_ratio = sum(1 for s in steps if s.citations) / len(steps)
        
        return 0.6 * avg_confidence + 0.4 * cited_ratio
    
    def _calculate_recency(self, dates: List[datetime] = None) -> float:
        """ุญุณุงุจ ุญุฏุงุซุฉ ุงููุนูููุงุช"""
        if not dates:
            return 0.7  # ุงูุชุฑุงุถู
        
        now = datetime.now()
        ages = [(now - d).days for d in dates if d]
        
        if not ages:
            return 0.7
        
        avg_age = np.mean(ages)
        
        if avg_age < 365:  # ุฃูู ูู ุณูุฉ
            return 0.95
        elif avg_age < 730:  # ุฃูู ูู ุณูุชูู
            return 0.85
        elif avg_age < 1825:  # ุฃูู ูู 5 ุณููุงุช
            return 0.7
        else:
            return 0.5


# ============================================================
# REASONING STRATEGIES
# ============================================================

class ReasoningStrategy(ABC):
    """ุงุณุชุฑุงุชูุฌูุฉ ุชูููุฑ ูุฌุฑุฏุฉ"""
    
    @abstractmethod
    def reason(
        self,
        question: str,
        context: str,
        sources: List[Dict],
        llm: Any
    ) -> Tuple[str, List[ReasoningStep], float]:
        """ุชูููุฐ ุงูุงุณุชุฏูุงู"""
        pass


class DirectStrategy(ReasoningStrategy):
    """ุงุณุชุฑุงุชูุฌูุฉ ุงูุฅุฌุงุจุฉ ุงููุจุงุดุฑุฉ"""
    
    def reason(self, question, context, sources, llm) -> Tuple[str, List[ReasoningStep], float]:
        prompt = f"""ุฃุฌุจ ุจุฅูุฌุงุฒ ูุฏูุฉ ุนูู ุงูุณุคุงู ุงูุชุงูู:

ุงูุณุคุงู: {question}

ุงููุนูููุงุช ุงููุชุงุญุฉ:
{context[:2000]}

ุงุณุชุดูุฏ ุจุงููุตุงุฏุฑ ุจูู ููุณูู [1], [2]."""

        response = llm.chat_completion(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        step = ReasoningStep(
            step_id=1,
            description="ุฅุฌุงุจุฉ ูุจุงุดุฑุฉ",
            reasoning_type=ReasoningMode.DEDUCTIVE,
            inputs=[question],
            output=response,
            confidence=0.7
        )
        
        return response, [step], 0.7


class ChainOfThoughtStrategy(ReasoningStrategy):
    """ุงุณุชุฑุงุชูุฌูุฉ ุงูุชูููุฑ ุงููุชุณูุณู"""
    
    def reason(self, question, context, sources, llm) -> Tuple[str, List[ReasoningStep], float]:
        steps = []
        
        # ุงูุฎุทูุฉ 1: ุชุญุฏูุฏ ุงูููุงุนุฏ
        step1_prompt = f"""ุญุฏุฏ ุงูููุงุนุฏ ุงููุงููููุฉ ุงูููุทุจูุฉ ุนูู:
ุงูุณุคุงู: {question}
ุงููุตุงุฏุฑ: {context[:1500]}

ุงุฐูุฑ ุงูููุงุนุฏ ููุท."""

        rules = llm.chat_completion(
            messages=[{"role": "user", "content": step1_prompt}],
            temperature=0.2
        )
        
        steps.append(ReasoningStep(
            step_id=1,
            description="ุชุญุฏูุฏ ุงูููุงุนุฏ ุงููุงููููุฉ",
            reasoning_type=ReasoningMode.DEDUCTIVE,
            inputs=[question],
            output=rules,
            confidence=0.8
        ))
        
        # ุงูุฎุทูุฉ 2: ุงูุชุทุจูู
        step2_prompt = f"""ุทุจูู ุงูููุงุนุฏ ุงูุชุงููุฉ ุนูู ุงูุณุคุงู:

ุงูููุงุนุฏ: {rules}
ุงูุณุคุงู: {question}

ูุง ุงููุชูุฌุฉุ"""

        application = llm.chat_completion(
            messages=[{"role": "user", "content": step2_prompt}],
            temperature=0.3
        )
        
        steps.append(ReasoningStep(
            step_id=2,
            description="ุชุทุจูู ุงูููุงุนุฏ",
            reasoning_type=ReasoningMode.DEDUCTIVE,
            inputs=[rules],
            output=application,
            confidence=0.75
        ))
        
        # ุงูุฎุทูุฉ 3: ุงูุงุณุชุซูุงุกุงุช
        step3_prompt = f"""ูู ููุงู ุงุณุชุซูุงุกุงุช ุนูู ุงููุชูุฌุฉ ุงูุชุงููุฉุ

ุงููุชูุฌุฉ: {application}
ุงูุณูุงู: {context[:1000]}

ุงุฐูุฑ ุงูุงุณุชุซูุงุกุงุช ุฅู ูุฌุฏุช."""

        exceptions = llm.chat_completion(
            messages=[{"role": "user", "content": step3_prompt}],
            temperature=0.3
        )
        
        steps.append(ReasoningStep(
            step_id=3,
            description="ูุญุต ุงูุงุณุชุซูุงุกุงุช",
            reasoning_type=ReasoningMode.ABDUCTIVE,
            inputs=[application],
            output=exceptions,
            confidence=0.7
        ))
        
        # ุงูุฎุทูุฉ 4: ุงูุฅุฌุงุจุฉ ุงูููุงุฆูุฉ
        final_prompt = f"""ุจูุงุกู ุนูู ุงูุชุญููู:
- ุงูููุงุนุฏ: {rules}
- ุงูุชุทุจูู: {application}
- ุงูุงุณุชุซูุงุกุงุช: {exceptions}

ูุฏูู ุงูุฅุฌุงุจุฉ ุงูููุงุฆูุฉ ููุณุคุงู: {question}"""

        final = llm.chat_completion(
            messages=[{"role": "user", "content": final_prompt}],
            temperature=0.3
        )
        
        steps.append(ReasoningStep(
            step_id=4,
            description="ุงูุฅุฌุงุจุฉ ุงูููุงุฆูุฉ",
            reasoning_type=ReasoningMode.DEDUCTIVE,
            inputs=[rules, application, exceptions],
            output=final,
            confidence=0.8
        ))
        
        avg_confidence = np.mean([s.confidence for s in steps])
        return final, steps, avg_confidence


class MultiPathStrategy(ReasoningStrategy):
    """ุงุณุชุฑุงุชูุฌูุฉ ุงููุณุงุฑุงุช ุงููุชุนุฏุฏุฉ"""
    
    def __init__(self, num_paths: int = 3):
        self.num_paths = num_paths
    
    def reason(self, question, context, sources, llm) -> Tuple[str, List[ReasoningStep], float]:
        paths = []
        steps = []
        
        perspectives = [
            "ูู ููุธูุฑ ุญูุงูุฉ ุงูุญููู",
            "ูู ููุธูุฑ ุงุณุชูุฑุงุฑ ุงููุนุงููุงุช",
            "ูู ููุธูุฑ ุงูุนุฏุงูุฉ ูุงูุฅูุตุงู"
        ]
        
        # ุชูููุฏ ูุณุงุฑุงุช ูุชุนุฏุฏุฉ
        for i, perspective in enumerate(perspectives[:self.num_paths]):
            prompt = f"""ุฃุฌุจ ุนูู ุงูุณุคุงู {perspective}:

ุงูุณุคุงู: {question}
ุงููุนูููุงุช: {context[:1500]}

ูุฏูู ุฅุฌุงุจุฉ ูุฎุชุตุฑุฉ."""

            path_answer = llm.chat_completion(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.5 + i * 0.1  # ุชูููุน
            )
            
            paths.append({
                "perspective": perspective,
                "answer": path_answer
            })
            
            steps.append(ReasoningStep(
                step_id=i + 1,
                description=f"ูุณุงุฑ: {perspective}",
                reasoning_type=ReasoningMode.ABDUCTIVE,
                inputs=[question],
                output=path_answer,
                confidence=0.7
            ))
        
        # ุฏูุฌ ุงููุณุงุฑุงุช
        merge_prompt = f"""ูุฏูู ุซูุงุซ ุฅุฌุงุจุงุช ูู ููุธูุฑุงุช ูุฎุชููุฉ:

{json.dumps(paths, ensure_ascii=False, indent=2)}

ุงูุณุคุงู ุงูุฃุตูู: {question}

1. ูู ุชุชูู ุงูุฅุฌุงุจุงุชุ
2. ุฅุฐุง ุงุฎุชููุชุ ูุง ุงูุฑุฃู ุงูุฑุงุฌุญ ูููุงุฐุงุ
3. ูุฏูู ุฅุฌุงุจุฉ ููุงุฆูุฉ ูุชูุงุฒูุฉ."""

        merged = llm.chat_completion(
            messages=[{"role": "user", "content": merge_prompt}],
            temperature=0.3
        )
        
        steps.append(ReasoningStep(
            step_id=len(perspectives) + 1,
            description="ุฏูุฌ ุงููุณุงุฑุงุช",
            reasoning_type=ReasoningMode.INDUCTIVE,
            inputs=[p["answer"] for p in paths],
            output=merged,
            confidence=0.85
        ))
        
        # ุญุณุงุจ ุงูุซูุฉ ุจูุงุกู ุนูู ุงุชูุงู ุงููุณุงุฑุงุช
        agreement = self._calculate_path_agreement(paths)
        final_confidence = 0.6 + agreement * 0.35
        
        return merged, steps, final_confidence
    
    def _calculate_path_agreement(self, paths: List[Dict]) -> float:
        """ุญุณุงุจ ุงุชูุงู ุงููุณุงุฑุงุช"""
        # ุชุญููู ุจุณูุท - ูู ุงููุงูุน ุณูุณุชุฎุฏู semantic similarity
        if len(paths) < 2:
            return 0.7
        
        # ููุชุฑุถ ุงุชูุงู ูุชูุณุท
        return 0.75


class TreeOfThoughtStrategy(ReasoningStrategy):
    """ุงุณุชุฑุงุชูุฌูุฉ ุดุฌุฑุฉ ุงูุชูููุฑ"""
    
    def __init__(self, max_depth: int = 3, branching: int = 2):
        self.max_depth = max_depth
        self.branching = branching
    
    def reason(self, question, context, sources, llm) -> Tuple[str, List[ReasoningStep], float]:
        steps = []
        
        # ุงูุฌุฐุฑ: ุชูููู ุงูุณุคุงู
        decompose_prompt = f"""ูููู ุงูุณุคุงู ุงูุชุงูู ุฅูู ุฃุณุฆูุฉ ูุฑุนูุฉ:

ุงูุณุคุงู: {question}

ุงุฐูุฑ 2-3 ุฃุณุฆูุฉ ูุฑุนูุฉ ูุฌุจ ุงูุฅุฌุงุจุฉ ุนูููุง ุฃููุงู."""

        sub_questions = llm.chat_completion(
            messages=[{"role": "user", "content": decompose_prompt}],
            temperature=0.3
        )
        
        steps.append(ReasoningStep(
            step_id=1,
            description="ุชูููู ุงูุณุคุงู",
            reasoning_type=ReasoningMode.ABDUCTIVE,
            inputs=[question],
            output=sub_questions,
            confidence=0.8
        ))
        
        # ุงูุฅุฌุงุจุฉ ุนูู ุงููุฑูุน
        branch_answers = []
        for i, sq in enumerate(sub_questions.split('\n')[:self.branching]):
            if not sq.strip():
                continue
                
            branch_prompt = f"""ุฃุฌุจ ุนูู ุงูุณุคุงู ุงููุฑุนู:
{sq}

ุจูุงุกู ุนูู:
{context[:1000]}"""

            branch_answer = llm.chat_completion(
                messages=[{"role": "user", "content": branch_prompt}],
                temperature=0.3
            )
            
            branch_answers.append(branch_answer)
            
            steps.append(ReasoningStep(
                step_id=i + 2,
                description=f"ูุฑุน {i+1}: {sq[:50]}...",
                reasoning_type=ReasoningMode.DEDUCTIVE,
                inputs=[sq],
                output=branch_answer,
                confidence=0.75
            ))
        
        # ุงูุชุฌููุน
        synthesis_prompt = f"""ุจูุงุกู ุนูู ุฅุฌุงุจุงุช ุงูุฃุณุฆูุฉ ุงููุฑุนูุฉ:

{chr(10).join(f'- {a}' for a in branch_answers)}

ุฃุฌุจ ุนูู ุงูุณุคุงู ุงูุฃุตูู: {question}"""

        final = llm.chat_completion(
            messages=[{"role": "user", "content": synthesis_prompt}],
            temperature=0.3
        )
        
        steps.append(ReasoningStep(
            step_id=len(steps) + 1,
            description="ุชุฌููุน ุงูุฅุฌุงุจุฉ ุงูููุงุฆูุฉ",
            reasoning_type=ReasoningMode.INDUCTIVE,
            inputs=branch_answers,
            output=final,
            confidence=0.85
        ))
        
        return final, steps, 0.8


class DebateStrategy(ReasoningStrategy):
    """ุงุณุชุฑุงุชูุฌูุฉ ุงูููุงุธุฑุฉ"""
    
    def reason(self, question, context, sources, llm) -> Tuple[str, List[ReasoningStep], float]:
        steps = []
        
        # ุงููููู ุงูุฃูู (ูุคูุฏ)
        pro_prompt = f"""ุฃูุช ูุญุงูู ุชุฏุงูุน ุนู ุงููููู ุงููุคูุฏ.

ุงูุณุคุงู: {question}
ุงููุนูููุงุช: {context[:1500]}

ูุฏูู ุญุฌุฌู ุงููุคูุฏุฉ."""

        pro_args = llm.chat_completion(
            messages=[{"role": "user", "content": pro_prompt}],
            temperature=0.4
        )
        
        steps.append(ReasoningStep(
            step_id=1,
            description="ุงูุญุฌุฌ ุงููุคูุฏุฉ",
            reasoning_type=ReasoningMode.DEDUCTIVE,
            inputs=[question],
            output=pro_args,
            confidence=0.7
        ))
        
        # ุงููููู ุงูุซุงูู (ูุนุงุฑุถ)
        con_prompt = f"""ุฃูุช ูุญุงูู ุชุฏุงูุน ุนู ุงููููู ุงููุนุงุฑุถ.

ุงูุณุคุงู: {question}
ุงููุนูููุงุช: {context[:1500]}

ูุฏูู ุญุฌุฌู ุงููุนุงุฑุถุฉ."""

        con_args = llm.chat_completion(
            messages=[{"role": "user", "content": con_prompt}],
            temperature=0.4
        )
        
        steps.append(ReasoningStep(
            step_id=2,
            description="ุงูุญุฌุฌ ุงููุนุงุฑุถุฉ",
            reasoning_type=ReasoningMode.DEDUCTIVE,
            inputs=[question],
            output=con_args,
            confidence=0.7
        ))
        
        # ุงูุญูู
        judge_prompt = f"""ุฃูุช ูุงุถู ูุญุงูุฏ.

ุงูุณุคุงู: {question}

ุงูุญุฌุฌ ุงููุคูุฏุฉ:
{pro_args}

ุงูุญุฌุฌ ุงููุนุงุฑุถุฉ:
{con_args}

ุจูุงุกู ุนูู ุงููุธุงู ุงูุณุนูุฏูุ ูุง ุงูุฑุฃู ุงูุฑุงุฌุญ ูููุงุฐุงุ"""

        verdict = llm.chat_completion(
            messages=[{"role": "user", "content": judge_prompt}],
            temperature=0.3
        )
        
        steps.append(ReasoningStep(
            step_id=3,
            description="ุงูุญูู ูุงูุชุฑุฌูุญ",
            reasoning_type=ReasoningMode.ABDUCTIVE,
            inputs=[pro_args, con_args],
            output=verdict,
            confidence=0.85
        ))
        
        return verdict, steps, 0.8


class AnalogicalStrategy(ReasoningStrategy):
    """ุงุณุชุฑุงุชูุฌูุฉ ุงูููุงุณ ุนูู ุงูุณูุงุจู"""
    
    def reason(self, question, context, sources, llm) -> Tuple[str, List[ReasoningStep], float]:
        steps = []
        
        # ุงูุจุญุซ ุนู ุณูุงุจู ูุดุงุจูุฉ
        similar_prompt = f"""ุงุจุญุซ ูู ุงููุนูููุงุช ุงูุชุงููุฉ ุนู ุญุงูุงุช ุฃู ุณูุงุจู ูุดุงุจูุฉ:

ุงูุณุคุงู: {question}
ุงููุตุงุฏุฑ: {context[:2000]}

ุงุฐูุฑ ุฃู ุณูุงุจู ุฃู ุญุงูุงุช ูุดุงุจูุฉ."""

        similar_cases = llm.chat_completion(
            messages=[{"role": "user", "content": similar_prompt}],
            temperature=0.3
        )
        
        steps.append(ReasoningStep(
            step_id=1,
            description="ุงูุจุญุซ ุนู ุณูุงุจู ูุดุงุจูุฉ",
            reasoning_type=ReasoningMode.ANALOGICAL,
            inputs=[question],
            output=similar_cases,
            confidence=0.7
        ))
        
        # ุงูููุงุณ
        analogy_prompt = f"""ุจูุงุกู ุนูู ุงูุณูุงุจู ุงููุดุงุจูุฉ:
{similar_cases}

ูุณ ุนูู ูุฐู ุงูุณูุงุจู ููุฅุฌุงุจุฉ ุนูู:
{question}

ูุถูุญ ูุฌู ุงูุดุจู ูุงูุงุฎุชูุงู."""

        analogy = llm.chat_completion(
            messages=[{"role": "user", "content": analogy_prompt}],
            temperature=0.3
        )
        
        steps.append(ReasoningStep(
            step_id=2,
            description="ุงูููุงุณ ูุงูุงุณุชูุชุงุฌ",
            reasoning_type=ReasoningMode.ANALOGICAL,
            inputs=[similar_cases],
            output=analogy,
            confidence=0.75
        ))
        
        return analogy, steps, 0.75


# ============================================================
# STRATEGY SELECTOR
# ============================================================

class StrategySelector:
    """ูุญุฏุฏ ุงูุงุณุชุฑุงุชูุฌูุฉ ุงูุฐูู"""
    
    def __init__(self):
        self.strategies: Dict[ThinkingStrategy, ReasoningStrategy] = {
            ThinkingStrategy.DIRECT: DirectStrategy(),
            ThinkingStrategy.CHAIN_OF_THOUGHT: ChainOfThoughtStrategy(),
            ThinkingStrategy.MULTI_PATH: MultiPathStrategy(),
            ThinkingStrategy.TREE_OF_THOUGHT: TreeOfThoughtStrategy(),
            ThinkingStrategy.DEBATE: DebateStrategy(),
            ThinkingStrategy.ANALOGICAL: AnalogicalStrategy(),
        }
        
        # ููุงุนุฏ ุงูุงุฎุชูุงุฑ
        self.complexity_mapping = {
            "simple": ThinkingStrategy.DIRECT,
            "moderate": ThinkingStrategy.CHAIN_OF_THOUGHT,
            "complex": ThinkingStrategy.MULTI_PATH,
            "very_complex": ThinkingStrategy.TREE_OF_THOUGHT
        }
    
    def select(
        self,
        question: str,
        complexity: str,
        domain: str,
        is_controversial: bool = False,
        has_precedents: bool = False
    ) -> ThinkingStrategy:
        """ุงุฎุชูุงุฑ ุงูุงุณุชุฑุงุชูุฌูุฉ ุงูููุงุณุจุฉ"""
        
        # ุฅุฐุง ูุงู ูุซูุฑุงู ููุฌุฏู โ ููุงุธุฑุฉ
        if is_controversial:
            return ThinkingStrategy.DEBATE
        
        # ุฅุฐุง ูุงูุช ููุงู ุณูุงุจู โ ููุงุณ
        if has_precedents and complexity in ["moderate", "complex"]:
            return ThinkingStrategy.ANALOGICAL
        
        # ุญุณุจ ุงูุชุนููุฏ
        return self.complexity_mapping.get(complexity, ThinkingStrategy.CHAIN_OF_THOUGHT)
    
    def get_strategy(self, strategy_type: ThinkingStrategy) -> ReasoningStrategy:
        """ุงูุญุตูู ุนูู ุงุณุชุฑุงุชูุฌูุฉ"""
        return self.strategies.get(strategy_type, DirectStrategy())


# ============================================================
# FEEDBACK LEARNING
# ============================================================

@dataclass
class FeedbackRecord:
    """ุณุฌู ุงูุชุบุฐูุฉ ุงูุฑุงุฌุนุฉ"""
    question_hash: str
    strategy_used: ThinkingStrategy
    confidence_predicted: float
    user_rating: Optional[float] = None  # 1-5
    was_correct: Optional[bool] = None
    timestamp: datetime = field(default_factory=datetime.now)


class FeedbackLearner:
    """ูุชุนูู ุงูุชุบุฐูุฉ ุงูุฑุงุฌุนุฉ"""
    
    def __init__(self):
        self.records: List[FeedbackRecord] = []
        self.strategy_performance: Dict[ThinkingStrategy, List[float]] = defaultdict(list)
    
    def record_interaction(
        self,
        question: str,
        strategy: ThinkingStrategy,
        confidence: float
    ) -> str:
        """ุชุณุฌูู ุชูุงุนู"""
        q_hash = hashlib.md5(question.encode()).hexdigest()[:10]
        
        record = FeedbackRecord(
            question_hash=q_hash,
            strategy_used=strategy,
            confidence_predicted=confidence
        )
        self.records.append(record)
        
        return q_hash
    
    def record_feedback(
        self,
        question_hash: str,
        rating: float = None,
        was_correct: bool = None
    ):
        """ุชุณุฌูู ุงูุชุบุฐูุฉ ุงูุฑุงุฌุนุฉ"""
        for record in reversed(self.records):
            if record.question_hash == question_hash:
                record.user_rating = rating
                record.was_correct = was_correct
                
                # ุชุญุฏูุซ ุฃุฏุงุก ุงูุงุณุชุฑุงุชูุฌูุฉ
                if rating:
                    self.strategy_performance[record.strategy_used].append(rating / 5.0)
                break
    
    def get_strategy_adjustment(self, strategy: ThinkingStrategy) -> float:
        """ุงูุญุตูู ุนูู ุชุนุฏูู ุงูุซูุฉ ููุงุณุชุฑุงุชูุฌูุฉ"""
        performances = self.strategy_performance.get(strategy, [])
        if len(performances) < 5:
            return 1.0  # ูุง ุชุนุฏูู
        
        avg_performance = np.mean(performances[-20:])  # ุขุฎุฑ 20
        return 0.8 + avg_performance * 0.4  # 0.8 to 1.2


# ============================================================
# ADVANCED THINKING LOOP
# ============================================================

class AdvancedThinkingLoop:
    """
    ุญููุฉ ุงูุชูููุฑ ุงูููุญุฏุฉ ุงููุชูุฏูุฉ
    
    ุชุฏูุฌ ุฌููุน ุงูุชูููุงุช ุงููุชูุฏูุฉ
    """
    
    def __init__(
        self,
        llm_client,
        search_tool=None,
        lookup_tool=None,
        enable_cache: bool = True,
        enable_feedback: bool = True
    ):
        # ุงูููููุงุช ุงูุฃุณุงุณูุฉ
        self.llm = llm_client
        self.search_tool = search_tool
        self.lookup_tool = lookup_tool
        
        # ุงูุฃูุธูุฉ ุงููุชูุฏูุฉ
        self.cache = ThinkingCache() if enable_cache else None
        self.confidence_calc = AdvancedConfidenceCalculator()
        self.strategy_selector = StrategySelector()
        self.feedback = FeedbackLearner() if enable_feedback else None
        
        # ุงููุญููุงุช
        self.query_generator = None  # ุณูุชู ุชูุฑูุฑู
        self.relevance_filter = None
        
        logger.info("๐ Advanced ThinkingLoop initialized")
    
    def think(self, input: ThinkingInput) -> ThinkingOutput:
        """ุชูููุฐ ุญููุฉ ุงูุชูููุฑ ุงููุชูุฏูุฉ"""
        start_time = time.time()
        trace = []
        
        # ===== ุงูุชุญูู ูู ุงููุงุด =====
        if self.cache:
            cached = self.cache.get(input)
            if cached:
                trace.append("โก ุชู ุงูุงุณุชุฑุฌุงุน ูู ุงููุงุด")
                return cached
        
        try:
            # ===== Step 0: ูุญุต ููุน ุงูุณุคุงู (ูุงูููู ุฃู ุนุงุฏู/ุชุฑุญูุจ) =====
            trace.append("โช ูุญุต ููุน ุงูุณุคุงู...")
            question_type = self._detect_question_type(input.question)
            
            # ุฅุฐุง ูุงู ุชุฑุญูุจ ุฃู ุณุคุงู ุนุงุฏู โ ุฑุฏ ูุจุงุดุฑ ุจุฏูู ุชูููุฑ
            if question_type == "greeting":
                trace.append("   ููุน ุงูุณุคุงู: ุชุฑุญูุจ/ูุญุงุฏุซุฉ ุนุงุฏูุฉ")
                return self._quick_greeting_response(input, trace, start_time)
            
            trace.append("   ููุน ุงูุณุคุงู: ุงุณุชูุณุงุฑ ูุงูููู")
            
            # ===== Step 1: ุชุญููู ุงูุณุคุงู =====
            trace.append("โ ุชุญููู ุงูุณุคุงู...")
            analysis = self._analyze_question(input.question)
            trace.append(f"   ุงููุฌุงู: {analysis['domain']}")
            trace.append(f"   ุงูุชุนููุฏ: {analysis['complexity']}")
            
            # ===== Step 2: ุงุฎุชูุงุฑ ุงูุงุณุชุฑุงุชูุฌูุฉ =====
            trace.append("โก ุงุฎุชูุงุฑ ุงูุงุณุชุฑุงุชูุฌูุฉ...")
            strategy = input.force_strategy or self.strategy_selector.select(
                question=input.question,
                complexity=analysis['complexity'],
                domain=analysis['domain'],
                is_controversial=analysis.get('is_controversial', False),
                has_precedents=analysis.get('has_precedents', False)
            )
            trace.append(f"   ุงูุงุณุชุฑุงุชูุฌูุฉ: {strategy.value}")
            
            # ===== Step 3: ุงูุจุญุซ =====
            trace.append("โข ุงูุจุญุซ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช...")
            raw_results = self._execute_search(analysis)
            trace.append(f"   ุชู ุฌูุจ {len(raw_results)} ูุชูุฌุฉ")
            
            # ===== Step 4: ุงูููุชุฑุฉ =====
            trace.append("โฃ ููุชุฑุฉ ุงููุชุงุฆุฌ...")
            filtered = self._filter_results(input.question, raw_results)
            trace.append(f"   ุชู ูุจูู {len(filtered['relevant'])}/{len(raw_results)}")
            
            relevant_sources = filtered['relevant']
            
            # ===== Step 5: ุจูุงุก ุงูุณูุงู =====
            trace.append("โค ุจูุงุก ุงูุณูุงู...")
            context = self._build_context(relevant_sources, input.context)
            
            # ===== Step 6: ุงูุชูููุฑ =====
            trace.append(f"โฅ ุงูุชูููุฑ ({strategy.value})...")
            reasoning_strategy = self.strategy_selector.get_strategy(strategy)
            answer, reasoning_steps, base_confidence = reasoning_strategy.reason(
                question=input.question,
                context=context,
                sources=relevant_sources,
                llm=self.llm
            )
            trace.append(f"   {len(reasoning_steps)} ุฎุทูุฉ ุชูููุฑ")
            
            # ===== Step 7: ูุฑุงุฌุนุฉ ุงููุจุงุฏุฆ =====
            trace.append("โฆ ูุฑุงุฌุนุฉ ุงููุจุงุฏุฆ...")
            principles = self._lookup_principles(analysis)
            if principles:
                trace.append(f"   {len(principles)} ูุจุฏุฃ ูุทุงุจู")
                answer = self._enhance_with_principles(answer, principles)
            
            # ===== Step 8: ุชุญููู ุฅุถุงูู =====
            counterfactuals = []
            deadline_alerts = []
            
            if input.include_counterfactuals:
                trace.append("โง ุชุญููู ุงูุจุฏูู ุงููุถุงุฏ...")
                counterfactuals = self._generate_counterfactuals(
                    input.question, answer, context
                )
            
            if input.check_deadlines:
                deadline_alerts = self._check_deadlines(input.question, context)
                if deadline_alerts:
                    trace.append(f"โ๏ธ {len(deadline_alerts)} ุชูุจูู ุจููุงุนูุฏ")
            
            # ===== Step 9: ุญุณุงุจ ุงูุซูุฉ =====
            trace.append("โจ ุญุณุงุจ ุงูุซูุฉ...")
            confidence_breakdown = self.confidence_calc.calculate(
                sources=relevant_sources,
                reasoning_steps=reasoning_steps,
                question_coverage=self._estimate_coverage(input.question, answer)
            )
            
            # ุชุนุฏูู ุจูุงุกู ุนูู ุงูุชุบุฐูุฉ ุงูุฑุงุฌุนุฉ
            if self.feedback:
                adjustment = self.feedback.get_strategy_adjustment(strategy)
                final_confidence = min(1.0, confidence_breakdown.overall * adjustment)
            else:
                final_confidence = confidence_breakdown.overall
            
            trace.append(f"   ุงูุซูุฉ: {final_confidence:.1%}")
            
            # ===== Step 10: ุจูุงุก ุงููุฎุฑุฌุงุช =====
            elapsed = (time.time() - start_time) * 1000
            trace.append(f"โ ุงูุชูู ูู {elapsed:.0f}ms")
            
            # ุงุณุชุฎุฑุงุฌ ุงูุงุณุชุดูุงุฏุงุช
            citations = self._extract_citations(answer, relevant_sources)
            
            # ุงูุชุญุฐูุฑุงุช
            warnings = self._generate_warnings(
                confidence=final_confidence,
                sources_count=len(relevant_sources),
                has_citations=len(citations) > 0
            )
            
            output = ThinkingOutput(
                answer=answer,
                summary=self._generate_summary(answer),
                confidence=final_confidence,
                confidence_breakdown=confidence_breakdown,
                confidence_level=ConfidenceLevel.from_score(final_confidence),
                strategy_used=strategy,
                reasoning_mode=self._get_primary_mode(reasoning_steps),
                domain=analysis['domain'],
                complexity=analysis['complexity'],
                sources_retrieved=len(raw_results),
                sources_used=len(relevant_sources),
                sources_filtered=len(filtered.get('excluded', [])),
                citations=citations,
                reasoning_steps=reasoning_steps,
                reasoning_trace=trace,
                counterfactuals=counterfactuals,
                deadline_alerts=deadline_alerts,
                related_questions=self._generate_related_questions(input.question),
                warnings=warnings,
                uncited_claims=self._find_uncited_claims(answer, citations),
                execution_time_ms=elapsed,
                cache_hit=False
            )
            
            # ุญูุธ ูู ุงููุงุด
            if self.cache:
                self.cache.set(input, output)
            
            # ุชุณุฌูู ููุชุบุฐูุฉ ุงูุฑุงุฌุนุฉ
            if self.feedback:
                self.feedback.record_interaction(
                    input.question, strategy, final_confidence
                )
            
            return output
            
        except Exception as e:
            logger.error(f"Thinking error: {e}")
            return self._create_error_output(input, str(e), trace, start_time)
    
    # ===== Helper Methods =====
    
    def _detect_question_type(self, question: str) -> str:
        """
        ุชุญุฏูุฏ ููุน ุงูุณุคุงู: ูุงูููู ุฃู ุนุงุฏู/ุชุฑุญูุจ
        
        Returns:
            "legal" - ุณุคุงู ูุงูููู ูุญุชุงุฌ ุชูููุฑ
            "greeting" - ุชุฑุญูุจ ุฃู ูุญุงุฏุซุฉ ุนุงุฏูุฉ
        """
        question_lower = question.lower()
        
        # ูููุงุช ุงูุชุฑุญูุจ ูุงููุญุงุฏุซุฉ ุงูุนุงุฏูุฉ
        greeting_patterns = [
            "ูุฑุญุจ", "ุฃููุง", "ุงูุณูุงู", "ุตุจุงุญ", "ูุณุงุก", "ููู ุญุงู", "ูููู",
            "ุดูููู", "ูุด ุงุฎุจุงุฑ", "ุดูุฑุง", "ุดูุฑุงู", "ุงููู ูุนุทูู", "ูุนุทูู ุงูุนุงููุฉ",
            "ุชุดุฑููุง", "ูู ุฃูุช", "ูู ุงูุช", "ูุง ุงุณูู", "ุงุด ุงุณูู","hello", "hi",
            "ุชุณุงุนุฏูู", "ูููู", "ูู ุณูุญุช", "ุฃุฑูุฏ ุงุณุชูุณุงุฑ", "ุนูุฏู ุณุคุงู",
            "ููู ุงุณุชุฎุฏู", "ููู ุงุดุชุบู", "ููู", "ููู", "ุดูู", "ุดุงูู"
        ]
        
        # ูููุงุช ูุงููููุฉ ูุงุถุญุฉ
        legal_keywords = [
            "ุญู", "ูุงููู", "ูุธุงู", "ูุญููุฉ", "ูุงุถู", "ุฏุนูู", "ุญูู", "ูุงุฏุฉ",
            "ุนูุฏ", "ุงุชูุงู", "ุงูุชุฒุงู", "ูุฎุงููุฉ", "ุฌุฑููุฉ", "ุนููุจุฉ", "ุญุถุงูุฉ",
            "ุทูุงู", "ูููุฉ", "ููุฑุงุซ", "ูุตูุฉ", "ุตู", "ุญุฌุฉ", "ุณูุฏ", "ูุซููุฉ",
            "ุงุณุชุฆูุงู", "ุงุนุชุฑุงุถ", "ุชุธูู", "ุดููู", "ุจูุงุบ", "ุชูููุฐ"
        ]
        
        # ูุญุต ุงูุชุฑุญูุจุงุช ุฃููุงู
        if any(pattern in question_lower for pattern in greeting_patterns):
            # ุฅูุง ุฅุฐุง ูุงูุช ุชุญุชูู ุนูู ูููุงุช ูุงููููุฉ (ูุซู: "ูุฑุญุจุงุ ุนูุฏู ุณุคุงู ุนู ุงูุนูุฏ")
            if not any(kw in question_lower for kw in legal_keywords):
                return "greeting"
        
        # ูุญุต ุงููุตุฑ (ุงูุฃุณุฆูุฉ ุงููุตูุฑุฉ ุฌุฏุงู ุบุงูุจุงู ุชุฑุญูุจุงุช)
        if len(question.split()) <= 2 and not any(kw in question_lower for kw in legal_keywords):
            return "greeting"
        
        # ุงูุงูุชุฑุงุถู: ุณุคุงู ูุงูููู
        return "legal"
    
    def _quick_greeting_response(
        self,
        input: ThinkingInput,
        trace: List[str],
        start_time: float
    ) -> ThinkingOutput:
        """ุฑุฏ ุณุฑูุน ุนูู ุงูุชุฑุญูุจุงุช ูุงูุฃุณุฆูุฉ ุงูุนุงุฏูุฉ"""
        question_lower = input.question.lower()
        
        # ุงุฎุชูุงุฑ ุงูุฑุฏ ุงูููุงุณุจ
        if any(word in question_lower for word in ["ูุฑุญุจ", "ุฃููุง", "ุงูุณูุงู", "ุตุจุงุญ", "ูุณุงุก"," hello", "hi"]):
            answer = "ูุฑุญุจุงู ุจู! ุฃูุง ูุณุงุนุฏู ุงููุงูููู ุงููุชุฎุตุต ูู ุงูุฃูุธูุฉ ุงูุณุนูุฏูุฉ. ููู ูููููู ูุณุงุนุฏุชู ุงููููุ"
        
        elif any(word in question_lower for word in ["ุดูุฑ", "ูุนุทูู", "ุงููู ูุฌุฒุงู"]):
            answer = "ุงูุนูู! ุณุนูุฏ ุจุฎุฏูุชู. ุฅุฐุง ูุงู ูุฏูู ุฃู ุงุณุชูุณุงุฑ ูุงูููู ุขุฎุฑุ ูุง ุชุชุฑุฏุฏ ุจุทุฑุญู."
        
        elif any(word in question_lower for word in ["ูู ุฃูุช", "ูู ุงูุช", "ูุง ุงุณูู", "ุงุด ุงุณูู"]):
            answer = "ุฃูุง ูุณุงุนุฏ ูุงูููู ุฐูู ููุชุฎุตุต ูู ุงูุฃูุธูุฉ ูุงูููุงุฆุญ ุงูุณุนูุฏูุฉ. ุฃุณุชุทูุน ูุณุงุนุฏุชู ูู ุงูุงุณุชูุณุงุฑุงุช ุงููุงููููุฉ ุงููุชุนููุฉ ุจุงูุฃุญูุงู ุงูุดุฎุตูุฉุ ุงูุนููุฏุ ุงูุนููุ ุงูุชุฌุงุฑุฉุ ูุงููุฒูุฏ."
        
        elif any(word in question_lower for word in ["ููู", "ูุด", "ุดููู", "ุงูุด"]) and not any(kw in question_lower for kw in ["ุญู", "ูุงููู", "ูุญููุฉ"]):
            answer = "ููููู ุณุคุงูู ุนู ุฃู ููุถูุน ูุงูููู ูุชุนูู ุจุงูุฃูุธูุฉ ุงูุณุนูุฏูุฉ. ุนูู ุณุจูู ุงููุซุงู:\nโข ุงูุฃุญูุงู ุงูุดุฎุตูุฉ (ุญุถุงูุฉุ  ูููุฉุ ุทูุงู)\nโข ุงูุนููุฏ ูุงูุงูุชุฒุงูุงุช\nโข ุงููุถุงูุง ุงูุฌูุงุฆูุฉ\nโข ูุงููู ุงูุนูู\nโข ุงูุชูููุฐ ูุงูุฅุฌุฑุงุกุงุช\n\nูุง ุงูุฐู ุชูุฏ ุงูุงุณุชูุณุงุฑ ุนููุ"
        
        else:
            answer = "ุฃููุงู ุจู! ุฃูุง ููุง ููุณุงุนุฏุชู ูู ุงูุงุณุชูุณุงุฑุงุช ุงููุงููููุฉ ุงููุชุนููุฉ ุจุงูุฃูุธูุฉ ุงูุณุนูุฏูุฉ. ููู ูููููู ุฎุฏูุชูุ"
        
        elapsed = (time.time() - start_time) * 1000
        trace.append(f"โ ุฑุฏ ุณุฑูุน ูู {elapsed:.0f}ms")
        
        return ThinkingOutput(
            answer=answer,
            summary="ุฑุฏ ุนูู ุชุญูุฉ/ุณุคุงู ุนุงุฏู",
            confidence=1.0,
            confidence_breakdown=ConfidenceBreakdown(1.0, 1.0, 1.0, 1.0, 1.0),
            confidence_level=ConfidenceLevel.VERY_HIGH,
            strategy_used=ThinkingStrategy.DIRECT,
            reasoning_mode=ReasoningMode.DEDUCTIVE,
            domain="general",
            complexity="simple",
            sources_retrieved=0,
            sources_used=0,
            sources_filtered=0,
            citations=[],
            reasoning_steps=[],
            reasoning_trace=trace,
            warnings=[],
            execution_time_ms=elapsed,
            cache_hit=False
        )
    
    def _analyze_question(self, question: str) -> Dict[str, Any]:
        """ุชุญููู ุงูุณุคุงู"""
        # ุชุญููู ูุจุณุท (ุณูุณุชุฎุฏู IntelligentQueryGenerator)
        complexity = "moderate"
        domain = "general"
        
        # ูููุงุช ุชุดูุฑ ููุชุนููุฏ
        complex_indicators = ["ุฅุฐุง", "ูู ุญุงูุฉ", "ูุง ุงููุฑู", "ูุงุฑู"]
        simple_indicators = ["ูุง ูู", "ูู", "ูุชู", "ุฃูู"]
        
        if any(ind in question for ind in complex_indicators):
            complexity = "complex"
        elif any(ind in question for ind in simple_indicators):
            complexity = "simple"
        
        # ูููุงุช ุงููุฌุงู
        domain_keywords = {
            "contracts": ["ุนูุฏ", "ุฅูุฌุงุฑ", "ุจูุน", "ูุณุฎ"],
            "criminal": ["ุฌุฑููุฉ", "ุนููุจุฉ", "ุฌูุงูุฉ"],
            "family": ["ุทูุงู", "ูููุฉ", "ุญุถุงูุฉ"],
            "labor": ["ุนูู", "ููุธู", "ูุตู", "ุฑุงุชุจ"]
        }
        
        for d, keywords in domain_keywords.items():
            if any(kw in question for kw in keywords):
                domain = d
                break
        
        return {
            "domain": domain,
            "complexity": complexity,
            "keywords": [],  # ุณูุชู ุงุณุชุฎุฑุงุฌูุง
            "is_controversial": False,
            "has_precedents": False
        }
    
    def _execute_search(self, analysis: Dict) -> List[Dict]:
        """ุชูููุฐ ุงูุจุญุซ"""
        if not self.search_tool:
            return []
        
        results = []
        queries = analysis.get('keywords', [analysis.get('domain', '')])
        
        for q in queries[:3]:
            try:
                result = self.search_tool.run(query=q, top_k=5)
                if result.success and result.data:
                    results.extend(result.data.get("results", []))
            except:
                pass
        
        # ุฅุฒุงูุฉ ุงูุชูุฑุงุฑุงุช
        seen = set()
        unique = []
        for r in results:
            rid = r.get("id", str(r))
            if rid not in seen:
                seen.add(rid)
                unique.append(r)
        
        return unique
    
    def _filter_results(self, question: str, results: List[Dict]) -> Dict:
        """ููุชุฑุฉ ุงููุชุงุฆุฌ"""
        relevant = []
        excluded = []
        
        for r in results:
            content = r.get("content", "")
            # ููุชุฑุฉ ุจุณูุทุฉ (ุณูุณุชุฎุฏู RelevanceFilter)
            if len(content) > 50:
                relevant.append(r)
            else:
                excluded.append(r)
        
        return {"relevant": relevant, "excluded": excluded}
    
    def _build_context(self, results: List[Dict], additional: str) -> str:
        """ุจูุงุก ุงูุณูุงู"""
        parts = []
        for i, r in enumerate(results[:10], 1):
            content = r.get("content", "")[:500]
            parts.append(f"[{i}] {content}")
        
        context = "\n\n".join(parts)
        if additional:
            context = f"{additional}\n\n---\n\n{context}"
        
        return context
    
    def _lookup_principles(self, analysis: Dict) -> List[Dict]:
        """ุงูุจุญุซ ุนู ุงููุจุงุฏุฆ"""
        if not self.lookup_tool:
            return []
        
        try:
            result = self.lookup_tool.run(
                query=analysis.get('domain', ''),
                top_k=3
            )
            return result.data.get("principles", []) if result.success else []
        except:
            return []
    
    def _enhance_with_principles(self, answer: str, principles: List[Dict]) -> str:
        """ุชุนุฒูุฒ ุจุงููุจุงุฏุฆ"""
        if not principles:
            return answer
        
        text = "\n\n**ุงููุจุงุฏุฆ ุงููุงููููุฉ:**\n"
        for p in principles[:3]:
            text += f"โข {p.get('text', '')[:150]}\n"
        
        return answer + text
    
    def _generate_counterfactuals(
        self, question: str, answer: str, context: str
    ) -> List[CounterfactualAnalysis]:
        """ุชูููุฏ ุงูุจุฏุงุฆู ุงููุถุงุฏุฉ"""
        # ุณูุณุชุฎุฏู CounterfactualReasoner
        return []
    
    def _check_deadlines(self, question: str, context: str) -> List[DeadlineAlert]:
        """ูุญุต ุงูููุงุนูุฏ"""
        # ุณูุณุชุฎุฏู TemporalReasoner
        alerts = []
        
        deadline_keywords = {
            "ุงุณุชุฆูุงู": 30,
            "ุงุนุชุฑุงุถ": 15,
            "ุชุธูู": 60
        }
        
        for keyword, days in deadline_keywords.items():
            if keyword in question or keyword in context:
                alerts.append(DeadlineAlert(
                    deadline_type=keyword,
                    deadline_date=datetime.now() + timedelta(days=days),
                    days_remaining=days,
                    action_required=f"ุชูุฏูู {keyword}",
                    legal_basis="ุงููุธุงู"
                ))
        
        return alerts
    
    def _estimate_coverage(self, question: str, answer: str) -> float:
        """ุชูุฏูุฑ ุชุบุทูุฉ ุงูุณุคุงู"""
        # ุชุญููู ุจุณูุท
        q_words = set(question.split())
        a_words = set(answer.split())
        overlap = len(q_words & a_words)
        return min(1.0, overlap / max(len(q_words), 1) * 2)
    
    def _extract_citations(
        self, answer: str, sources: List[Dict]
    ) -> List[Citation]:
        """ุงุณุชุฎุฑุงุฌ ุงูุงุณุชุดูุงุฏุงุช"""
        citations = []
        
        # ุงูุจุญุซ ุนู [1], [2], ุฅูุฎ
        import re
        refs = re.findall(r'\[(\d+)\]', answer)
        
        for ref in refs:
            idx = int(ref) - 1
            if 0 <= idx < len(sources):
                s = sources[idx]
                citations.append(Citation(
                    source_id=s.get("id", f"src_{idx}"),
                    source_type=s.get("type", "article"),
                    text=s.get("content", "")[:100],
                    relevance_score=s.get("score", 0.7)
                ))
        
        return citations
    
    def _generate_warnings(
        self,
        confidence: float,
        sources_count: int,
        has_citations: bool
    ) -> List[str]:
        """ุชูููุฏ ุงูุชุญุฐูุฑุงุช"""
        warnings = []
        
        if confidence < 0.5:
            warnings.append("โ๏ธ ุฏุฑุฌุฉ ุงูุซูุฉ ููุฎูุถุฉุ ูููุตุญ ุจูุฑุงุฌุนุฉ ูุญุงูู")
        
        if sources_count < 2:
            warnings.append("โ๏ธ ูุตุงุฏุฑ ูุญุฏูุฏุฉุ ูุฏ ุชุญุชุงุฌ ุจุญุซุงู ุฅุถุงููุงู")
        
        if not has_citations:
            warnings.append("โ๏ธ ุงูุฅุฌุงุจุฉ ุบูุฑ ููุซูุฉ ุจูุตุงุฏุฑ ูุญุฏุฏุฉ")
        
        return warnings
    
    def _generate_summary(self, answer: str) -> str:
        """ุชูููุฏ ููุฎุต"""
        # ุฃูู 200 ุญุฑู
        if len(answer) <= 200:
            return answer
        return answer[:200] + "..."
    
    def _get_primary_mode(self, steps: List[ReasoningStep]) -> ReasoningMode:
        """ุชุญุฏูุฏ ููุท ุงูุชูููุฑ ุงูุฃุณุงุณู"""
        if not steps:
            return ReasoningMode.DEDUCTIVE
        
        modes = [s.reasoning_type for s in steps]
        return max(set(modes), key=modes.count)
    
    def _generate_related_questions(self, question: str) -> List[str]:
        """ุชูููุฏ ุฃุณุฆูุฉ ุฐุงุช ุตูุฉ"""
        # ูุจุณุท
        return [
            f"ูุง ุงูุฅุฌุฑุงุกุงุช ุงููุชุจุนุฉ ูู ูุฐู ุงูุญุงูุฉุ",
            f"ูู ููุงู ุงุณุชุซูุงุกุงุชุ",
            f"ูุง ุงูููุงุนูุฏ ุงููุงููููุฉ ุงููููุฉุ"
        ]
    
    def _find_uncited_claims(
        self, answer: str, citations: List[Citation]
    ) -> List[str]:
        """ุฅูุฌุงุฏ ุงูุงุฏุนุงุกุงุช ุบูุฑ ุงูููุซูุฉ"""
        # ูุจุณุท - ุณูุณุชุฎุฏู NLP
        if citations:
            return []
        
        # ุฅุฐุง ูุง ุชูุฌุฏ ุงุณุชุดูุงุฏุงุช
        claims = []
        strong_words = ["ูุฌุจ", "ูุญุธุฑ", "ููุฒู", "ูุงุฌุจ"]
        
        for word in strong_words:
            if word in answer:
                claims.append(f"ุงุฏุนุงุก ูุญุชูู ุนูู '{word}' ุจุฏูู ูุตุฏุฑ")
        
        return claims[:3]
    
    def _create_error_output(
        self,
        input: ThinkingInput,
        error: str,
        trace: List[str],
        start_time: float
    ) -> ThinkingOutput:
        """ุฅูุดุงุก ูุฎุฑุฌุงุช ุฎุทุฃ"""
        elapsed = (time.time() - start_time) * 1000
        trace.append(f"โ ุฎุทุฃ: {error}")
        
        return ThinkingOutput(
            answer=f"ุนุฐุฑุงูุ ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ูุนุงูุฌุฉ ุงูุณุคุงู: {error}",
            summary="ุฎุทุฃ ูู ุงููุนุงูุฌุฉ",
            confidence=0.0,
            confidence_breakdown=ConfidenceBreakdown(0, 0, 0, 0, 0),
            confidence_level=ConfidenceLevel.VERY_LOW,
            strategy_used=ThinkingStrategy.DIRECT,
            reasoning_mode=ReasoningMode.DEDUCTIVE,
            domain="unknown",
            complexity="unknown",
            sources_retrieved=0,
            sources_used=0,
            sources_filtered=0,
            citations=[],
            reasoning_steps=[],
            reasoning_trace=trace,
            warnings=[f"ุฎุทุฃ: {error}"],
            execution_time_ms=elapsed
        )


# ============================================================
# EXPORTS
# ============================================================

__all__ = [
    "ThinkingStrategy",
    "ThinkingInput",
    "ThinkingOutput",
    "AdvancedThinkingLoop",
    "ConfidenceLevel",
    "ReasoningMode",
    "Citation",
    "ReasoningStep"
]