"""
Relevance Filter System
Ù†Ø¸Ø§Ù… ÙÙ„ØªØ±Ø© Ø§Ù„ØµÙ„Ø© - ÙŠÙ‚ÙŠÙ‘Ù… ÙˆÙŠÙÙ„ØªØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ØºÙŠØ± Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©

Features:
- Topic matching with semantic understanding
- Legal domain verification
- Context fitness scoring
- Auto-exclusion of irrelevant results
"""

import logging
import json
import re
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass

from .intelligent_prompts import (
    LegalDomain,
    LEGAL_DOMAIN_KEYWORDS,
    PromptBuilder
)
from ..config.openwebui import openwebui_client

logger = logging.getLogger(__name__)


@dataclass
class RelevanceScore:
    """Ù†ØªÙŠØ¬Ø© ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØµÙ„Ø©"""
    content_id: str
    topic_match: float      # 0-1: Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹
    domain_match: float     # 0-1: Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù…Ø¬Ø§Ù„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ
    context_fit: float      # 0-1: Ù…Ù†Ø§Ø³Ø¨Ø© Ø§Ù„Ø³ÙŠØ§Ù‚
    overall_score: float    # 0-1: Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
    is_relevant: bool       # Ù‡Ù„ Ø°Ùˆ ØµÙ„Ø©ØŸ
    reason: str             # Ø³Ø¨Ø¨ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…


class RelevanceFilter:
    """
    Ù…Ø±Ø´Ù‘Ø­ Ø§Ù„ØµÙ„Ø© Ù„Ù„Ù†ØªØ§Ø¦Ø¬
    
    ÙŠØ³ØªØ®Ø¯Ù… Ø·Ø±ÙŠÙ‚ØªÙŠÙ†:
    1. Fast Filter: ÙÙ„ØªØ±Ø© Ø³Ø±ÙŠØ¹Ø© Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
    2. Deep Filter: ÙÙ„ØªØ±Ø© Ø¹Ù…ÙŠÙ‚Ø© Ø¨Ø§Ù„Ù€ LLM
    """
    
    # Thresholds
    RELEVANCE_THRESHOLD = 0.4   # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„ØµÙ„Ø©
    HIGH_CONFIDENCE = 0.7       # ØµÙ„Ø© Ø¹Ø§Ù„ÙŠØ©
    FAST_FILTER_THRESHOLD = 0.3 # Ø­Ø¯ Ø§Ù„ÙÙ„ØªØ±Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©
    
    def __init__(self, use_llm: bool = True):
        self.use_llm = use_llm
        self.prompt_builder = PromptBuilder()
        self.llm = openwebui_client
        logger.info(f"ğŸ” RelevanceFilter initialized (LLM={use_llm})")
    
    def filter_results(
        self,
        question: str,
        results: List[Dict[str, Any]],
        domain: LegalDomain = LegalDomain.UNKNOWN,
        keywords: List[str] = None
    ) -> Tuple[List[Dict[str, Any]], List[RelevanceScore]]:
        """
        ØªØµÙÙŠØ© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø§Ù„ØµÙ„Ø©
        
        Returns:
            (relevant_results, all_scores)
        """
        if not results:
            return [], []
        
        logger.info(f"ğŸ” Filtering {len(results)} results for relevance...")
        
        # Extract keywords if not provided
        if not keywords:
            keywords = self._extract_question_keywords(question)
        
        all_scores = []
        relevant_results = []
        
        for result in results:
            content = self._get_content(result)
            content_id = result.get("id", "unknown")
            
            # Stage 1: Fast filter (keyword-based)
            fast_score = self._fast_relevance_check(content, keywords, domain)
            
            if fast_score < self.FAST_FILTER_THRESHOLD:
                # Ø¥Ø³ØªØ¨Ø¹Ø§Ø¯ Ø³Ø±ÙŠØ¹
                score = RelevanceScore(
                    content_id=content_id,
                    topic_match=fast_score,
                    domain_match=0.0,
                    context_fit=0.0,
                    overall_score=fast_score,
                    is_relevant=False,
                    reason="ÙØ´Ù„ Ø§Ù„ÙÙ„ØªØ±Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø© - Ù„Ø§ ØªÙˆØ¬Ø¯ ÙƒÙ„Ù…Ø§Øª Ø¯Ø§Ù„Ø©"
                )
                all_scores.append(score)
                continue
            
            # Stage 2: Deep filter (LLM-based) for borderline cases
            if self.use_llm and fast_score < self.HIGH_CONFIDENCE:
                score = self._deep_relevance_check(question, content, domain, content_id)
            else:
                # Score is high enough, accept without LLM
                score = RelevanceScore(
                    content_id=content_id,
                    topic_match=fast_score,
                    domain_match=self._domain_match(content, domain),
                    context_fit=fast_score,
                    overall_score=fast_score,
                    is_relevant=True,
                    reason="Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"
                )
            
            all_scores.append(score)
            
            if score.is_relevant:
                result["relevance_score"] = score.overall_score
                relevant_results.append(result)
        
        # Sort by relevance
        relevant_results.sort(key=lambda x: x.get("relevance_score", 0), reverse=True)
        
        logger.info(f"âœ… Filtered: {len(relevant_results)}/{len(results)} relevant")
        
        return relevant_results, all_scores
    
    def _get_content(self, result: Dict[str, Any]) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø©"""
        content = (
            result.get("content") or 
            result.get("template_text") or 
            result.get("title") or
            result.get("full_content_md") or
            str(result)
        )
        return content[:2000]  # ØªÙ‚Ù„ÙŠØµ Ù„Ù„Ø£Ø¯Ø§Ø¡
    
    def _extract_question_keywords(self, question: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ù† Ø§Ù„Ø³Ø¤Ø§Ù„"""
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ
        words = re.findall(r'[\u0600-\u06FF]+', question)
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        stop_words = {
            "ÙÙŠ", "Ù…Ù†", "Ø¥Ù„Ù‰", "Ø¹Ù„Ù‰", "Ø¹Ù†", "Ù‡Ù„", "Ù…Ø§", "Ù‡ÙŠ", "Ù‡Ùˆ", 
            "Ø£Ù†", "ÙƒØ§Ù†", "Ø§Ù„ØªÙŠ", "Ø§Ù„Ø°ÙŠ", "Ù‡Ø°Ø§", "Ù‡Ø°Ù‡", "Ø¨Ø¹Ø¯", "Ù‚Ø¨Ù„",
            "Ø­ÙˆÙ„", "Ø¹Ù†Ø¯", "ÙƒÙ„", "Ø¨ÙŠÙ†", "Ø¥Ø°Ø§", "Ø«Ù…", "Ø£Ùˆ", "Ùˆ"
        }
        
        keywords = [w for w in words if len(w) > 2 and w not in stop_words]
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
        for domain_keywords in LEGAL_DOMAIN_KEYWORDS.values():
            for kw in domain_keywords:
                if kw in question and kw not in keywords:
                    keywords.append(kw)
        
        return keywords[:15]
    
    def _fast_relevance_check(
        self,
        content: str,
        keywords: List[str],
        domain: LegalDomain
    ) -> float:
        """ÙØ­Øµ Ø³Ø±ÙŠØ¹ Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
        if not content or not keywords:
            return 0.0
        
        content_lower = content.lower()
        
        # Ø­Ø³Ø§Ø¨ ØªØ·Ø§Ø¨Ù‚ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
        matches = 0
        for kw in keywords:
            if kw in content:
                matches += 1
        
        keyword_score = matches / len(keywords) if keywords else 0
        
        # Ø­Ø³Ø§Ø¨ ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù…Ø¬Ø§Ù„
        domain_score = self._domain_match(content, domain)
        
        # Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ¨Ø©
        overall = (keyword_score * 0.7) + (domain_score * 0.3)
        
        return min(1.0, overall)
    
    def _domain_match(self, content: str, domain: LegalDomain) -> float:
        """Ø­Ø³Ø§Ø¨ ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù…Ø¬Ø§Ù„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ"""
        if domain == LegalDomain.UNKNOWN:
            return 0.5  # Ù…Ø­Ø§ÙŠØ¯
        
        domain_keywords = LEGAL_DOMAIN_KEYWORDS.get(domain, [])
        if not domain_keywords:
            return 0.5
        
        matches = sum(1 for kw in domain_keywords if kw in content)
        score = min(1.0, matches / 5)  # Ù†Ø­ØªØ§Ø¬ 5 ÙƒÙ„Ù…Ø§Øª Ù„Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
        
        return score
    
    def _deep_relevance_check(
        self,
        question: str,
        content: str,
        domain: LegalDomain,
        content_id: str
    ) -> RelevanceScore:
        """ÙØ­Øµ Ø¹Ù…ÙŠÙ‚ Ø¨Ø§Ù„Ù€ LLM"""
        try:
            prompt = self.prompt_builder.build_relevance_prompt(
                question=question,
                content=content[:1000],
                domain=domain.value.replace("_", " ")
            )
            
            response = self.llm.chat_completion(
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ù…Ø¯Ù‚Ù‚ ØµÙ„Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠ. Ø£Ø¬Ø¨ Ø¨Ù€ JSON ÙÙ‚Ø·."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=300
            )
            
            # Parse JSON response
            result = self._parse_json(response)
            
            topic_match = float(result.get("topic_match", 0.5))
            domain_match = float(result.get("domain_match", 0.5))
            context_fit = float(result.get("context_fit", 0.5))
            overall = float(result.get("overall_relevance", (topic_match + domain_match + context_fit) / 3))
            
            return RelevanceScore(
                content_id=content_id,
                topic_match=topic_match,
                domain_match=domain_match,
                context_fit=context_fit,
                overall_score=overall,
                is_relevant=overall >= self.RELEVANCE_THRESHOLD,
                reason=result.get("reason", "ØªÙ‚ÙŠÙŠÙ… LLM")
            )
            
        except Exception as e:
            logger.error(f"Deep relevance check failed: {e}")
            # Fallback to fast filter
            return RelevanceScore(
                content_id=content_id,
                topic_match=0.5,
                domain_match=0.5,
                context_fit=0.5,
                overall_score=0.5,
                is_relevant=True,  # ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£ Ù†Ù‚Ø¨Ù„
                reason=f"Fallback due to error: {str(e)[:50]}"
            )
    
    def _parse_json(self, text: str) -> Dict[str, Any]:
        """Parse JSON from LLM response"""
        try:
            # Try direct parse
            if text.strip().startswith("{"):
                return json.loads(text.strip())
            
            # Find JSON in text
            if "```json" in text:
                json_str = text.split("```json")[1].split("```")[0].strip()
            elif "```" in text:
                json_str = text.split("```")[1].split("```")[0].strip()
            else:
                start = text.find("{")
                end = text.rfind("}") + 1
                json_str = text[start:end] if start != -1 else "{}"
            
            return json.loads(json_str)
        except:
            return {}


class SmartSearcher:
    """
    Ø¨Ø§Ø­Ø« Ø°ÙƒÙŠ ÙŠØ¯Ù…Ø¬ Ø§Ù„Ø¨Ø­Ø« Ù…Ø¹ Ø§Ù„ÙÙ„ØªØ±Ø©
    """
    
    def __init__(self, relevance_filter: RelevanceFilter = None):
        self.filter = relevance_filter or RelevanceFilter()
        self.prompt_builder = PromptBuilder()
        logger.info("ğŸ” SmartSearcher initialized")
    
    def search_and_filter(
        self,
        question: str,
        search_results: List[Dict[str, Any]],
        min_relevance: float = 0.4,
        max_results: int = 10
    ) -> Dict[str, Any]:
        """
        Ø¨Ø­Ø« ÙˆÙÙ„ØªØ±Ø© Ø°ÙƒÙŠØ©
        
        Returns:
            {
                "relevant": [...],
                "excluded": [...],
                "stats": {...}
            }
        """
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„
        analyzed = self.prompt_builder.query_generator.analyze_question(question)
        
        # ÙÙ„ØªØ±Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        relevant, scores = self.filter.filter_results(
            question=question,
            results=search_results,
            domain=analyzed.domain,
            keywords=analyzed.legal_keywords
        )
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        excluded = [s for s in scores if not s.is_relevant]
        
        # Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        stats = {
            "total_results": len(search_results),
            "relevant_count": len(relevant),
            "excluded_count": len(excluded),
            "domain": analyzed.domain.value,
            "keywords_used": analyzed.legal_keywords,
            "avg_relevance": sum(s.overall_score for s in scores) / len(scores) if scores else 0
        }
        
        logger.info(f"ğŸ“Š Search stats: {stats['relevant_count']}/{stats['total_results']} relevant")
        
        return {
            "relevant": relevant[:max_results],
            "excluded": [{"id": s.content_id, "reason": s.reason} for s in excluded],
            "scores": scores,
            "stats": stats,
            "analysis": analyzed
        }


# =============================================================================
# EXPORTS
# =============================================================================

__all__ = [
    "RelevanceScore",
    "RelevanceFilter",
    "SmartSearcher"
]
