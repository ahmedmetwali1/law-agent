"""
Self-Consistency Reasoning Engine with Legal Conflict Resolution
Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø§Ø³Ù‚ Ø§Ù„Ø°Ø§ØªÙŠ Ù…Ø¹ Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©

Enhanced Features:
- Multi-path generation with different perspectives
- Legal Conflict Resolution (not just majority voting)
- Citation Mapping for all claims
- Confidence calibration
- Contradiction detection with deep analysis
"""

import logging
import json
import time
import re
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
from collections import Counter

from .intelligent_prompts import (
    LegalDomain,
    MAGIC_WORDS,
    PromptBuilder
)
from ..config.openwebui import openwebui_client

logger = logging.getLogger(__name__)


class ReasoningPerspective(Enum):
    """ÙˆØ¬Ù‡Ø§Øª Ø§Ù„Ù†Ø¸Ø± Ù„Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…ØªØ¹Ø¯Ø¯"""
    LEGAL_EXPERT = "Ø®Ø¨ÙŠØ±_Ù‚Ø§Ù†ÙˆÙ†ÙŠ"
    JUDGE = "Ù‚Ø§Ø¶ÙŠ"
    OPPOSING_COUNSEL = "Ù…Ø­Ø§Ù…ÙŠ_Ø®ØµÙ…"
    PRACTICAL = "ØªØ·Ø¨ÙŠÙ‚ÙŠ"
    TEXTUAL = "Ù†ØµÙŠ_Ø­Ø±ÙÙŠ"


@dataclass
class Citation:
    """Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¨Ù…ØµØ¯Ø±"""
    chunk_id: str
    source_id: str
    content_snippet: str
    relevance_score: float


@dataclass 
class CitedClaim:
    """Ø§Ø¯Ø¹Ø§Ø¡ Ù…ÙˆØ«Ù‚ Ø¨Ù…ØµØ¯Ø±"""
    claim: str
    citations: List[Citation]
    has_source: bool
    confidence: float


@dataclass
class ReasoningPath:
    """Ù…Ø³Ø§Ø± ØªÙÙƒÙŠØ± ÙˆØ§Ø­Ø¯"""
    path_id: int
    perspective: ReasoningPerspective
    reasoning: str
    conclusion: str
    confidence: float
    key_points: List[str]
    source_ids: List[str] = field(default_factory=list)  # Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
    execution_time_ms: float = 0.0


@dataclass
class LegalConflict:
    """ØªØ¹Ø§Ø±Ø¶ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø¨ÙŠÙ† Ù…Ø³Ø§Ø±ÙŠÙ†"""
    path_a: ReasoningPath
    path_b: ReasoningPath
    conflict_type: str  # "newer_vs_older", "specific_vs_general", "exception_vs_rule"
    resolution: str
    winning_path_id: int
    analysis: str


@dataclass
class ConsistencyResult:
    """Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªÙ†Ø§Ø³Ù‚ Ø§Ù„Ø°Ø§ØªÙŠ"""
    final_answer: str
    confidence: float
    paths_count: int
    agreement_ratio: float
    majority_conclusion: str
    contradictions: List[str]
    conflicts_resolved: List[LegalConflict]
    cited_claims: List[CitedClaim]
    uncited_warnings: List[str]
    reasoning_summary: str
    all_paths: List[ReasoningPath]


class SelfConsistencyEngine:
    """
    Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø§Ø³Ù‚ Ø§Ù„Ø°Ø§ØªÙŠ Ù…Ø¹ Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
    
    ÙŠÙˆÙ„Ù‘Ø¯ 3-5 Ù…Ø³Ø§Ø±Ø§Øª ØªÙÙƒÙŠØ± Ù…Ø®ØªÙ„ÙØ© ÙˆÙŠØ­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø¨Ø°ÙƒØ§Ø¡
    """
    
    DEFAULT_PATHS = 3
    MAX_PATHS = 5
    
    # ÙˆØ¬Ù‡Ø§Øª Ø§Ù„Ù†Ø¸Ø± ÙˆØªØ±ÙƒÙŠØ²Ù‡Ø§
    PERSPECTIVES_CONFIG = {
        ReasoningPerspective.LEGAL_EXPERT: {
            "role": "Ø£Ù†Øª Ù…Ø­Ø§Ù…Ù Ø³Ø¹ÙˆØ¯ÙŠ Ø®Ø¨ÙŠØ± Ø¨Ø®Ø¨Ø±Ø© 20 Ø¹Ø§Ù…Ø§Ù‹",
            "focus": "Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ÙˆØ§Ù„Ø£Ù†Ø¸Ù…Ø© ÙˆØ§Ù„Ø³ÙˆØ§Ø¨Ù‚",
            "magic": MAGIC_WORDS["step_by_step"][0]
        },
        ReasoningPerspective.JUDGE: {
            "role": "Ø£Ù†Øª Ù‚Ø§Ø¶Ù ÙÙŠ Ù…Ø­ÙƒÙ…Ø© Ø§Ù„Ø£Ø­ÙˆØ§Ù„ Ø§Ù„Ø´Ø®ØµÙŠØ©",
            "focus": "ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† ÙˆØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ø¹Ø¯Ø§Ù„Ø©",
            "magic": MAGIC_WORDS["verification"][0]
        },
        ReasoningPerspective.OPPOSING_COUNSEL: {
            "role": "Ø£Ù†Øª Ù…Ø­Ø§Ù…ÙŠ Ø§Ù„Ø·Ø±Ù Ø§Ù„Ø¢Ø®Ø± ØªØ¨Ø­Ø« Ø¹Ù† Ø«ØºØ±Ø§Øª",
            "focus": "Ø§Ù„Ø­Ø¬Ø¬ Ø§Ù„Ù…Ø¶Ø§Ø¯Ø© ÙˆØ§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¡Ø§Øª",
            "magic": MAGIC_WORDS["counter_argument"][0]
        },
        ReasoningPerspective.PRACTICAL: {
            "role": "Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø¹Ù…Ù„ÙŠ",
            "focus": "Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ ÙˆØ¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù…Ø­Ø§ÙƒÙ…",
            "magic": MAGIC_WORDS["expert_role"][0]
        },
        ReasoningPerspective.TEXTUAL: {
            "role": "Ø£Ù†Øª Ø¨Ø§Ø­Ø« Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø¯Ù‚ÙŠÙ‚",
            "focus": "Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø­Ø±ÙÙŠØ© ÙˆØ§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ÙˆØ«ÙˆÙ‚Ø©",
            "magic": MAGIC_WORDS["deep_thinking"][0]
        }
    }
    
    def __init__(self):
        self.llm = openwebui_client
        self.prompt_builder = PromptBuilder()
        self.available_sources: Dict[str, Dict] = {}  # Ù„Ù„ØªØªØ¨Ø¹
        logger.info("ğŸ”„ SelfConsistencyEngine initialized with Legal Conflict Resolution")
    
    def set_available_sources(self, sources: List[Dict[str, Any]]):
        """ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯"""
        self.available_sources = {}
        for s in sources:
            source_id = s.get("id") or s.get("chunk_id") or str(len(self.available_sources))
            self.available_sources[source_id] = s
        logger.info(f"ğŸ“š Set {len(self.available_sources)} available sources for citation")
    
    def reason_with_consistency(
        self,
        question: str,
        context: str,
        sources: List[Dict[str, Any]] = None,
        domain: LegalDomain = LegalDomain.UNKNOWN,
        num_paths: int = None
    ) -> ConsistencyResult:
        """
        ØªÙÙƒÙŠØ± Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ù…Ø¹ ØªÙ†Ø§Ø³Ù‚ Ø°Ø§ØªÙŠ ÙˆØ­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª
        """
        start_time = time.time()
        num_paths = min(num_paths or self.DEFAULT_PATHS, self.MAX_PATHS)
        
        # ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…ØµØ§Ø¯Ø±
        if sources:
            self.set_available_sources(sources)
        
        logger.info(f"ğŸ”„ Starting enhanced self-consistency with {num_paths} paths...")
        
        # Ø§Ø®ØªÙŠØ§Ø± ÙˆØ¬Ù‡Ø§Øª Ø§Ù„Ù†Ø¸Ø±
        perspectives = self._select_perspectives(domain, num_paths)
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
        paths = []
        for i, perspective in enumerate(perspectives):
            path = self._generate_reasoning_path(
                path_id=i + 1,
                perspective=perspective,
                question=question,
                context=context,
                domain=domain
            )
            paths.append(path)
            logger.info(f"   Path {i+1}/{num_paths} ({perspective.value}): confidence={path.confidence:.2f}")
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ†Ø§Ø³Ù‚ Ù…Ø¹ Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª
        result = self._analyze_consistency_enhanced(question, paths, context)
        
        elapsed = (time.time() - start_time) * 1000
        logger.info(f"âœ… Self-consistency complete in {elapsed:.0f}ms: agreement={result.agreement_ratio:.2f}, conflicts_resolved={len(result.conflicts_resolved)}")
        
        return result
    
    def _select_perspectives(
        self, 
        domain: LegalDomain, 
        num_paths: int
    ) -> List[ReasoningPerspective]:
        """Ø§Ø®ØªÙŠØ§Ø± ÙˆØ¬Ù‡Ø§Øª Ø§Ù„Ù†Ø¸Ø± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©"""
        perspectives = [
            ReasoningPerspective.LEGAL_EXPERT,
            ReasoningPerspective.JUDGE
        ]
        
        if domain == LegalDomain.PERSONAL_STATUS:
            perspectives.append(ReasoningPerspective.PRACTICAL)
        elif domain == LegalDomain.CRIMINAL:
            perspectives.append(ReasoningPerspective.TEXTUAL)
        else:
            perspectives.append(ReasoningPerspective.OPPOSING_COUNSEL)
        
        all_perspectives = list(ReasoningPerspective)
        for p in all_perspectives:
            if len(perspectives) >= num_paths:
                break
            if p not in perspectives:
                perspectives.append(p)
        
        return perspectives[:num_paths]
    
    def _generate_reasoning_path(
        self,
        path_id: int,
        perspective: ReasoningPerspective,
        question: str,
        context: str,
        domain: LegalDomain
    ) -> ReasoningPath:
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ø³Ø§Ø± ØªÙÙƒÙŠØ± ÙˆØ§Ø­Ø¯ Ù…Ø¹ ØªØªØ¨Ø¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±"""
        start_time = time.time()
        
        config = self.PERSPECTIVES_CONFIG[perspective]
        
        prompt = f"""{config['role']}

{config['magic']}

**Ø§Ù„Ø³Ø¤Ø§Ù„:** {question}

**Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØ§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª:**
{context[:1500]}

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:**
Ù…Ù† ÙˆØ¬Ù‡Ø© Ù†Ø¸Ø±Ùƒ ÙƒÙ€{perspective.value}ØŒ ÙˆØ¨Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ {config['focus']}:

1. Ø­Ù„Ù„ Ø§Ù„Ù…Ø³Ø£Ù„Ø© Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©
2. Ø­Ø¯Ø¯ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (3-5 Ù†Ù‚Ø§Ø·)
3. Ø­Ø¯Ø¯ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„ØªÙŠ ØªØ³ØªÙ†Ø¯ Ø¥Ù„ÙŠÙ‡Ø§ (Ù…Ù† [1] Ø¥Ù„Ù‰ [10])
4. Ù‚Ø¯Ù‘Ù… Ø§Ø³ØªÙ†ØªØ§Ø¬Ùƒ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
5. Ù‚ÙŠÙ‘Ù… Ù…Ø³ØªÙˆÙ‰ Ø«Ù‚ØªÙƒ (0-1)

**Ø£Ø¬Ø¨ Ø¨Ù€ JSON:**
{{
    "reasoning": "ØªØ­Ù„ÙŠÙ„Ùƒ Ø§Ù„Ù…ÙØµÙ„ Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©",
    "key_points": ["Ù†Ù‚Ø·Ø© 1", "Ù†Ù‚Ø·Ø© 2", "Ù†Ù‚Ø·Ø© 3"],
    "source_refs": [1, 2, 5],
    "conclusion": "Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙÙŠ Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø©",
    "confidence": 0.0-1.0
}}"""

        try:
            response = self.llm.chat_completion(
                messages=[
                    {"role": "system", "content": f"Ø£Ù†Øª {config['role']}. ÙÙƒÙ‘Ø± Ø¨Ø¹Ù…Ù‚ ÙˆØ£Ø¬Ø¨ Ø¨Ù€ JSON. Ø§Ø³ØªÙ†Ø¯ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ù„Ù„Ù…ØµØ§Ø¯Ø±."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1200
            )
            
            result = self._parse_json(response)
            elapsed = (time.time() - start_time) * 1000
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø´Ø§Ø± Ø¥Ù„ÙŠÙ‡Ø§
            source_refs = result.get("source_refs", [])
            source_ids = [str(ref) for ref in source_refs if isinstance(ref, (int, str))]
            
            return ReasoningPath(
                path_id=path_id,
                perspective=perspective,
                reasoning=result.get("reasoning", response[:500]),
                conclusion=result.get("conclusion", "Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø§Ø³ØªÙ†ØªØ§Ø¬"),
                confidence=float(result.get("confidence", 0.5)),
                key_points=result.get("key_points", []),
                source_ids=source_ids,
                execution_time_ms=elapsed
            )
            
        except Exception as e:
            logger.error(f"Path generation failed: {e}")
            return ReasoningPath(
                path_id=path_id,
                perspective=perspective,
                reasoning=f"ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}",
                conclusion="ØºÙŠØ± Ù…ØªØ§Ø­",
                confidence=0.0,
                key_points=[],
                source_ids=[],
                execution_time_ms=(time.time() - start_time) * 1000
            )
    
    def _analyze_consistency_enhanced(
        self,
        question: str,
        paths: List[ReasoningPath],
        context: str
    ) -> ConsistencyResult:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ†Ø§Ø³Ù‚ Ù…Ø¹ Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©"""
        
        if not paths:
            return ConsistencyResult(
                final_answer="Ù„Ù… ÙŠØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø©",
                confidence=0.0,
                paths_count=0,
                agreement_ratio=0.0,
                majority_conclusion="",
                contradictions=[],
                conflicts_resolved=[],
                cited_claims=[],
                uncited_warnings=[],
                reasoning_summary="Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø³Ø§Ø±Ø§Øª",
                all_paths=[]
            )
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙˆØ§ÙÙ‚
        agreement = self._calculate_agreement(paths)
        
        # ÙƒØ´Ù Ø§Ù„ØªÙ†Ø§Ù‚Ø¶Ø§Øª
        contradictions = self._detect_contradictions(paths)
        
        # Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© (Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ù…Ø¬Ø±Ø¯ Ø§Ù„ØªØµÙˆÙŠØª)
        conflicts_resolved = []
        if contradictions:
            conflicts_resolved = self._resolve_legal_conflicts(paths, context)
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª
        if conflicts_resolved:
            majority = self._conclusion_from_conflicts(paths, conflicts_resolved)
        else:
            majority = self._majority_vote(paths)
        
        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        final_answer = self._synthesize_answer(question, paths, majority, conflicts_resolved)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø§Ø¯Ø¹Ø§Ø¡Ø§Øª Ù…Ø¹ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯Ø§Øª
        cited_claims, uncited_warnings = self._extract_citations(final_answer)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø©
        avg_confidence = sum(p.confidence for p in paths) / len(paths)
        conflict_penalty = 0.1 * len(contradictions) if contradictions else 0
        citation_bonus = 0.1 if len(uncited_warnings) == 0 else 0
        final_confidence = min(1.0, avg_confidence * agreement - conflict_penalty + citation_bonus)
        
        # Ù…Ù„Ø®Øµ Ø§Ù„ØªÙÙƒÙŠØ±
        summary = self._create_summary(paths, conflicts_resolved)
        
        return ConsistencyResult(
            final_answer=final_answer,
            confidence=final_confidence,
            paths_count=len(paths),
            agreement_ratio=agreement,
            majority_conclusion=majority,
            contradictions=contradictions,
            conflicts_resolved=conflicts_resolved,
            cited_claims=cited_claims,
            uncited_warnings=uncited_warnings,
            reasoning_summary=summary,
            all_paths=paths
        )
    
    def _resolve_legal_conflicts(
        self,
        paths: List[ReasoningPath],
        context: str
    ) -> List[LegalConflict]:
        """Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¨Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ‚"""
        conflicts = []
        
        # Ø¥ÙŠØ¬Ø§Ø¯ Ø£Ø²ÙˆØ§Ø¬ Ù…ØªØ¹Ø§Ø±Ø¶Ø©
        for i in range(len(paths)):
            for j in range(i + 1, len(paths)):
                p1, p2 = paths[i], paths[j]
                
                # ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ØªØ¹Ø§Ø±Ø¶ Ø­Ù‚ÙŠÙ‚ÙŠ
                if abs(p1.confidence - p2.confidence) > 0.3:
                    conflict = self._analyze_conflict(p1, p2, context)
                    if conflict:
                        conflicts.append(conflict)
                        logger.info(f"âš–ï¸ Resolved conflict: {conflict.conflict_type} -> Path {conflict.winning_path_id}")
        
        return conflicts[:3]  # Ø£Ù‚ØµÙ‰ 3 ØªØ¹Ø§Ø±Ø¶Ø§Øª
    
    def _analyze_conflict(
        self,
        path_a: ReasoningPath,
        path_b: ReasoningPath,
        context: str
    ) -> Optional[LegalConflict]:
        """ØªØ­Ù„ÙŠÙ„ ØªØ¹Ø§Ø±Ø¶ ÙˆØ§Ø­Ø¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚"""
        
        prompt = f"""Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©.

**Ø§Ù„ØªØ¹Ø§Ø±Ø¶:**
- Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø£ÙˆÙ„ ({path_a.perspective.value}): {path_a.conclusion}
  Ø§Ù„Ø«Ù‚Ø©: {path_a.confidence:.1f}
  
- Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø«Ø§Ù†ÙŠ ({path_b.perspective.value}): {path_b.conclusion}
  Ø§Ù„Ø«Ù‚Ø©: {path_b.confidence:.1f}

**Ø§Ù„Ø³ÙŠØ§Ù‚:**
{context[:1000]}

**Ø­Ù„Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶ ÙˆØ­Ø¯Ø¯:**
1. Ù†ÙˆØ¹ Ø§Ù„ØªØ¹Ø§Ø±Ø¶:
   - newer_vs_older: Ù†Øµ Ø£Ø­Ø¯Ø« ÙŠÙ„ØºÙŠ Ø§Ù„Ø£Ù‚Ø¯Ù…
   - specific_vs_general: Ù†Øµ Ø®Ø§Øµ ÙŠÙ‚ÙŠØ¯ Ø§Ù„Ø¹Ø§Ù…
   - exception_vs_rule: Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ù„Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¹Ø§Ù…Ø©
   - interpretation_diff: Ø§Ø®ØªÙ„Ø§Ù ÙÙŠ Ø§Ù„ØªÙØ³ÙŠØ± ÙÙ‚Ø·
   
2. Ø£ÙŠ Ø§Ù„Ø±Ø£ÙŠÙŠÙ† Ø£ØµØ­ ÙˆÙ„Ù…Ø§Ø°Ø§ØŸ

**Ø£Ø¬Ø¨ Ø¨Ù€ JSON:**
{{
    "conflict_type": "Ù†ÙˆØ¹ Ø§Ù„ØªØ¹Ø§Ø±Ø¶",
    "winning_opinion": 1 Ø£Ùˆ 2,
    "analysis": "ØªØ­Ù„ÙŠÙ„ Ù…Ø®ØªØµØ± Ù„Ù„Ø³Ø¨Ø¨",
    "resolution": "ÙƒÙŠÙ ØªÙ… Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶"
}}"""

        try:
            response = self.llm.chat_completion(
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª. Ø£Ø¬Ø¨ Ø¨Ù€ JSON."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=500
            )
            
            result = self._parse_json(response)
            
            winning = result.get("winning_opinion", 1)
            
            return LegalConflict(
                path_a=path_a,
                path_b=path_b,
                conflict_type=result.get("conflict_type", "interpretation_diff"),
                resolution=result.get("resolution", "Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯"),
                winning_path_id=path_a.path_id if winning == 1 else path_b.path_id,
                analysis=result.get("analysis", "")
            )
            
        except Exception as e:
            logger.error(f"Conflict analysis failed: {e}")
            return None
    
    def _conclusion_from_conflicts(
        self,
        paths: List[ReasoningPath],
        conflicts: List[LegalConflict]
    ) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª"""
        # ØªØ±Ø¬ÙŠØ­ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ÙØ§Ø¦Ø²Ø©
        winning_ids = [c.winning_path_id for c in conflicts]
        
        for path in paths:
            if path.path_id in winning_ids:
                return path.conclusion
        
        # Fallback
        return max(paths, key=lambda p: p.confidence).conclusion
    
    def _extract_citations(
        self,
        answer: str
    ) -> Tuple[List[CitedClaim], List[str]]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø§Ø¯Ø¹Ø§Ø¡Ø§Øª ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯Ø§Øª"""
        cited_claims = []
        uncited_warnings = []
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù„Ø¬Ù…Ù„
        sentences = re.split(r'[.ØŒØ›]', answer)
        
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) < 20:  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
                continue
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¥Ø´Ø§Ø±Ø§Øª Ù„Ù„Ù…ØµØ§Ø¯Ø± [1], [2], etc.
            source_refs = re.findall(r'\[(\d+)\]', sentence)
            
            if source_refs:
                # Ø¬Ù…Ù„Ø© Ù…ÙˆØ«Ù‚Ø©
                citations = []
                for ref in source_refs:
                    if ref in self.available_sources:
                        src = self.available_sources[ref]
                        citations.append(Citation(
                            chunk_id=src.get("id", ref),
                            source_id=src.get("source_id", ""),
                            content_snippet=src.get("content", "")[:100],
                            relevance_score=src.get("relevance_score", 0.5)
                        ))
                
                cited_claims.append(CitedClaim(
                    claim=sentence,
                    citations=citations,
                    has_source=len(citations) > 0,
                    confidence=0.9 if citations else 0.5
                ))
            else:
                # Ø§Ø¯Ø¹Ø§Ø¡ Ø¨Ø¯ÙˆÙ† Ù…ØµØ¯Ø±
                # ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ø¯Ø¹Ø§Ø¡Ù‹ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ§Ù‹ ÙŠØ­ØªØ§Ø¬ ØªÙˆØ«ÙŠÙ‚
                if self._is_legal_claim(sentence):
                    uncited_warnings.append(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ØµØ¯Ø±: Â«{sentence[:50]}...Â»")
        
        return cited_claims, uncited_warnings
    
    def _is_legal_claim(self, sentence: str) -> bool:
        """ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ø¯Ø¹Ø§Ø¡Ù‹ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ§Ù‹ ÙŠØ­ØªØ§Ø¬ ØªÙˆØ«ÙŠÙ‚"""
        legal_indicators = [
            "ÙŠØ¬Ø¨", "Ù„Ø§ ÙŠØ¬ÙˆØ²", "Ø­Ù‚", "ÙˆØ§Ø¬Ø¨", "ÙŠØ­Ø¸Ø±", "ÙŠÙ„Ø²Ù…",
            "Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†", "Ø§Ù„Ù†Ø¸Ø§Ù…", "Ø§Ù„Ù…Ø§Ø¯Ø©", "Ø§Ù„ÙÙ‚Ø±Ø©", "Ø§Ù„Ù…Ø­ÙƒÙ…Ø©",
            "Ø§Ù„Ø­ÙƒÙ…", "Ø§Ù„Ù‚Ø§Ø¶ÙŠ", "Ø§Ù„Ù‚Ø¶Ø§Ø¡", "Ø§Ù„Ø´Ø±ÙŠØ¹Ø©", "Ø§Ù„ÙÙ‚Ù‡"
        ]
        
        return any(ind in sentence for ind in legal_indicators)
    
    def _calculate_agreement(self, paths: List[ReasoningPath]) -> float:
        """Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙˆØ§ÙÙ‚ Ø¨ÙŠÙ† Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª"""
        if len(paths) < 2:
            return 1.0
        
        all_points = []
        for p in paths:
            all_points.extend(p.key_points)
        
        if not all_points:
            return 0.5
        
        point_counts = Counter(all_points)
        common_points = sum(1 for count in point_counts.values() if count > 1)
        
        agreement = common_points / len(set(all_points)) if all_points else 0.5
        
        confidences = [p.confidence for p in paths]
        confidence_variance = max(confidences) - min(confidences) if confidences else 0
        confidence_factor = 1 - (confidence_variance * 0.3)
        
        return min(1.0, agreement * confidence_factor + 0.3)
    
    def _majority_vote(self, paths: List[ReasoningPath]) -> str:
        """Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹"""
        weighted_conclusions = {}
        for p in paths:
            if p.conclusion:
                key = p.conclusion[:100]
                weighted_conclusions[key] = weighted_conclusions.get(key, 0) + p.confidence
        
        if weighted_conclusions:
            return max(weighted_conclusions, key=weighted_conclusions.get)
        
        best_path = max(paths, key=lambda p: p.confidence)
        return best_path.conclusion
    
    def _detect_contradictions(self, paths: List[ReasoningPath]) -> List[str]:
        """ÙƒØ´Ù Ø§Ù„ØªÙ†Ø§Ù‚Ø¶Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª"""
        contradictions = []
        
        for i in range(len(paths)):
            for j in range(i + 1, len(paths)):
                p1, p2 = paths[i], paths[j]
                
                if abs(p1.confidence - p2.confidence) > 0.4:
                    contradictions.append(
                        f"ØªØ¨Ø§ÙŠÙ† ÙƒØ¨ÙŠØ± Ø¨ÙŠÙ† {p1.perspective.value} ({p1.confidence:.1f}) Ùˆ {p2.perspective.value} ({p2.confidence:.1f})"
                    )
        
        return contradictions[:3]
    
    def _synthesize_answer(
        self,
        question: str,
        paths: List[ReasoningPath],
        majority: str,
        conflicts: List[LegalConflict]
    ) -> str:
        """ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù…Ø¹ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙˆÙ„Ø©"""
        
        conflict_notes = ""
        if conflicts:
            conflict_notes = "\n**Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø­ÙˆÙ„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙˆÙ„Ø©:**\n"
            for c in conflicts:
                conflict_notes += f"- {c.conflict_type}: {c.resolution}\n"
        
        prompt = f"""Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ù…Ù† ÙˆØ¬Ù‡Ø§Øª Ù†Ø¸Ø± Ù…Ø®ØªÙ„ÙØ©:

**Ø§Ù„Ø³Ø¤Ø§Ù„:** {question}

**Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ:** {majority}

**Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:**
{self._collect_key_points(paths)}

{conflict_notes}

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:**
1. Ø§ÙƒØªØ¨ Ø¥Ø¬Ø§Ø¨Ø© Ù†Ù‡Ø§Ø¦ÙŠØ© Ø´Ø§Ù…Ù„Ø© ÙˆÙ…ØªÙˆØ§Ø²Ù†Ø©
2. Ù„ÙƒÙ„ Ø§Ø¯Ø¹Ø§Ø¡ Ù‚Ø§Ù†ÙˆÙ†ÙŠØŒ Ø£Ø¶Ù Ø±Ù‚Ù… Ø§Ù„Ù…ØµØ¯Ø± Ø¨ÙŠÙ† Ù‚ÙˆØ³ÙŠÙ† Ù…Ø±Ø¨Ø¹ÙŠÙ† [1], [2] etc.
3. Ø§Ø°ÙƒØ± Ø£ÙŠ Ø§Ø³ØªØ«Ù†Ø§Ø¡Ø§Øª Ø£Ùˆ ØªØ­ÙØ¸Ø§Øª Ù…Ù‡Ù…Ø©

**Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:**"""

        try:
            response = self.llm.chat_completion(
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ù…Ø­Ø§Ù…Ù Ø®Ø¨ÙŠØ±. Ù‚Ø¯Ù‘Ù… Ø¥Ø¬Ø§Ø¨Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ØªÙˆØ§Ø²Ù†Ø© Ù…Ø¹ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¨Ø§Ù„Ù…ØµØ§Ø¯Ø±."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1500
            )
            return response
        except:
            return majority
    
    def _collect_key_points(self, paths: List[ReasoningPath]) -> str:
        """Ø¬Ù…Ø¹ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
        points = []
        for p in paths:
            for point in p.key_points[:2]:
                if point not in points:
                    points.append(f"- {point}")
        return "\n".join(points[:10])
    
    def _create_summary(
        self, 
        paths: List[ReasoningPath],
        conflicts: List[LegalConflict]
    ) -> str:
        """Ù…Ù„Ø®Øµ Ø§Ù„ØªÙÙƒÙŠØ±"""
        perspectives = [p.perspective.value for p in paths]
        avg_conf = sum(p.confidence for p in paths) / len(paths) if paths else 0
        
        summary = f"ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ù† {len(paths)} ÙˆØ¬Ù‡Ø§Øª Ù†Ø¸Ø± ({', '.join(perspectives)}) Ø¨Ù…ØªÙˆØ³Ø· Ø«Ù‚Ø© {avg_conf:.2f}"
        
        if conflicts:
            summary += f". ØªÙ… Ø­Ù„ {len(conflicts)} ØªØ¹Ø§Ø±Ø¶ Ù‚Ø§Ù†ÙˆÙ†ÙŠ."
        
        return summary
    
    def _parse_json(self, text: str) -> Dict[str, Any]:
        """Parse JSON from response"""
        try:
            if text.strip().startswith("{"):
                return json.loads(text.strip())
            
            if "```json" in text:
                json_str = text.split("```json")[1].split("```")[0].strip()
            elif "```" in text:
                json_str = text.split("```")[1].split("```")[0].strip()
            else:
                start = text.find("{")
                end = text.rfind("}") + 1
                json_str = text[start:end] if start != -1 else "{}"
            
            return json.loads(json_str)
        except:
            return {}


# =============================================================================
# EXPORTS
# =============================================================================

__all__ = [
    "ReasoningPerspective",
    "ReasoningPath",
    "Citation",
    "CitedClaim",
    "LegalConflict",
    "ConsistencyResult",
    "SelfConsistencyEngine"
]
